{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0ec7d8b7",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: obj_setup.html\n",
    "title: '04: Object setup'\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb8bc66-030c-4580-95bb-e8ec541d0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp obj_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39676ad-3c6d-4aa3-b710-fc019f6cd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev \n",
    "from nbdev import nbdev_export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef6d3d-7aa5-428c-99df-e9251ca3756e",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935cd9af-35cf-4e8e-8c9f-87c1a5c50569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import tarfile\n",
    "from owslib.wfs import WebFeatureService\n",
    "from requests import Request\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import s3fs\n",
    "# to get and use geojson datacube catalog\n",
    "import logging\n",
    "\n",
    "# for timing data access\n",
    "import time\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import s3fs as s3\n",
    "# for datacube xarra\n",
    "from pyproj import Transformer\n",
    "\n",
    "# for plotting time series\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw\n",
    "from ipywidgets import HTML\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d483c241-c631-4c02-8598-819b400d7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ITS_LIVE_TOOL import datacube_tools, interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19783ed-6583-421e-b74a-07176ec3227e",
   "metadata": {},
   "source": [
    "## Defining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcd3e2e-b6af-493b-bbd8-4c3d07ac8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def point_to_gdf(point_ls):\n",
    "    '''\n",
    "    creates a geodataframe from a given point\n",
    "\n",
    "    input: list of [x,y] coords\n",
    "    output: geopandas gdf of point, in epsg:4326\n",
    "    '''\n",
    "        \n",
    "    d = {'x': point_ls[0],\n",
    "         'y': point_ls[1]}\n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry = gpd.points_from_xy(df.x, df.y, crs='EPSG:4326'))\n",
    "    return gdf\n",
    "\n",
    "def swap_time_dim(ds):\n",
    "    '''this function does a few main things:\n",
    "    1. creates a numeric time dimension (off of mid-date) and swaps that for mid-date to be a dim\n",
    "    2. creates a temporal baseline variable (img_separation)\n",
    "    3. creates a variable called obs id that is meant to be a unique identifier for each time step since the mid-date indexer is non unique\n",
    "    4. removes empty time steps \n",
    "    '''\n",
    "    #add a numeric time dimensions\n",
    "    ds['time_numeric'] = ds.mid_date.dt.year + ds.mid_date.dt.dayofyear / 365\n",
    "    ds = ds.swap_dims({'mid_date':'time_numeric'})\n",
    "\n",
    "    #add numeric versions of img date 1, 2\n",
    "    ds['img1_numeric'] = ds.acquisition_date_img1.dt.year + ds.acquisition_date_img1.dt.dayofyear / 365\n",
    "    ds['img2_numeric'] = ds.acquisition_date_img2.dt.year + ds.acquisition_date_img2.dt.dayofyear / 365\n",
    "\n",
    "    #add temp baseline as a coordinate\n",
    "    ds = ds.assign_coords({'img_separation': ds.img_separation})\n",
    "\n",
    "    #sort by time dimension\n",
    "    ds = ds.sortby('time_numeric')\n",
    "    #add unique identifier\n",
    "    ds['obs_id'] = (('time_numeric'), range(len(ds['time_numeric'])))\n",
    "    ds = ds.assign_coords({'obs_id':ds['obs_id']})\n",
    "    # drop empty time steps\n",
    "    ds = ds.dropna(how='all', dim='time_numeric', subset='v')\n",
    "    return ds\n",
    "\n",
    "#def add_unique_ids(ds):\n",
    "\n",
    "#    ds = ds.sortby('time_numeric')\n",
    "#    ds['obs_id'] = (('time_numeric'), range(len(ds['time_numeric'])))\n",
    "#    ds = ds.assign_coords({'obs_id':ds['obs_id']})\n",
    "#    return ds\n",
    "    \n",
    "def drop_empty_timesteps(ds):\n",
    "    ds = ds.dropna(how='all', dim='time_numeric', subset='v')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cf69e0-68a1-4cb8-acc0-d779c26f0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Glacier_Centerline():\n",
    "    '''class to hold all data associated with a centerline'''\n",
    "    def __init__(self, name, rgi_id):\n",
    "        self.name = name\n",
    "        self.rgi_id = rgi_id\n",
    "        self.rgi_region = rgi_id.split('-')[1].split('.')[0]\n",
    "        self._centerline_path = self._download_centerlines()\n",
    "        self.centerlines, self.main_centerline, self.utm_zone = self._add_centerlines()\n",
    "        #self.padded_centerline_subcube = self._extract_subcube_along_padded_centerline()\n",
    "\n",
    "    def _download_centerlines(self, dest_folder = os.getcwd()):\n",
    "        '''function to download oggm centerlines by rgi region. \n",
    "        destination folder is a 'centerlines dir in the root folder\n",
    "        ''' \n",
    "        os.makedirs(dest_folder.split('nbs')[0]+'centerlines', exist_ok=True)\n",
    "        dest_folder = dest_folder.split('nbs')[0]+'centerlines/'\n",
    "    \n",
    "        #this first part of htis function is scraping the urls for OGGM centerlines for each RGI region from the summary page\n",
    "        # and organizing them into a dict \n",
    "        # hardcoded -- this is the link to OGGM centerlines separated into rgi regions -- each is compressed as tar.gz\n",
    "        orig_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L1-L2_files/centerlines/RGI62/b_010/L2/summary/'\n",
    "        response = requests.get(orig_url)\n",
    "        link_header = orig_url.split('~oggm')[0][:-1] #isolate just the beginning\n",
    "            \n",
    "        #print('link header :', link_header)\n",
    "        #link_header = 'https://cluster.klima.uni-bremen.de'\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        header = soup.find('h1') #this points to the summary page containing links for all regions \n",
    "        gen_link = str(header).split(' ')[2].split('<')[0]\n",
    "        data_url_gen = link_header + gen_link + '/' #this is the full url to the summary paeg\n",
    "        links = soup.find_all('a') #find all the links contained in page\n",
    "        \n",
    "        smoothed_flag = 'smoothed' # want only 'centerlines', not smoothed centerlines -- can change this\n",
    "        region_ls, region_url_ls = [],[]\n",
    "        \n",
    "        for link in range(len(links)): #this loop creates a dict where each key is an rgi region and each value is the url to that regions oggm centerlines\n",
    "            if links[link].attrs['href'].startswith('centerlines'):\n",
    "        \n",
    "                if smoothed_flag not in links[link].attrs['href']:\n",
    "                    region = links[link]['href'].split('_')[1].split('.')[0]\n",
    "                    region_url = data_url_gen+ links[link]['href']\n",
    "                    region_ls.append(region)\n",
    "                    region_url_ls.append(region_url)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "        region_url_dict = dict(zip(region_ls, region_url_ls))\n",
    "        rgi_region_code = self.rgi_region\n",
    "    \n",
    "        region_centerline_url = region_url_dict[rgi_region_code]\n",
    "        #print('url for specified region : ', region_centerline_url)\n",
    "        \n",
    "        #download_extract(region_centerline_url, dest_folder = dest_folder)\n",
    "    \n",
    "        #the second part of this function is reading the specified url, and downloading + extracting the file to a specified location\n",
    "        \n",
    "        #help from https://stackoverflow.com/questions/56950987/download-file-from-url-and-save-it-in-a-folder-python\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "    \n",
    "        filename = region_centerline_url.split('/')[-1].replace(\" \", \"_\")\n",
    "        file_path = os.path.join(dest_folder, filename)\n",
    "        #print(file_path)\n",
    "    \n",
    "        r = requests.get(region_centerline_url, stream=True)\n",
    "        if r.ok:\n",
    "            #print('saving to: ', os.path.abspath(file_path))\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=1024*8):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        f.flush()\n",
    "                        os.fsync(f.fileno())\n",
    "                    else:\n",
    "                        print('donwload failed')\n",
    "    \n",
    "        \n",
    "        file = tarfile.open(file_path)\n",
    "        file.extractall(dest_folder)\n",
    "    \n",
    "        #return the path to the shp file\n",
    "        a = file_path.split('tar.gz')[0] + 'shp'\n",
    "        #print(a)\n",
    "        return a\n",
    "\n",
    "    def _add_centerlines(self):\n",
    "        '''function to add gpd.geodataframe of oggm centerlines as an attribute to glacier centerline object\n",
    "        '''\n",
    "        gpdf = gpd.read_file(self._centerline_path)\n",
    "\n",
    "        gpdf = gpdf.loc[gpdf['RGIID'] == self.rgi_id]\n",
    "        utm = str(gpdf.estimate_utm_crs())\n",
    "        \n",
    "        gpdf_main = gpdf.loc[gpdf['MAIN'] == 1].to_crs(utm)\n",
    "        gpdf_all = gpdf.to_crs(utm)\n",
    "        return gpdf_all, gpdf_main, utm\n",
    "\n",
    "    #def _extract_subcube_along_padded_centerline(self, pad=200):\n",
    "    # removing because this pulls the subucbe around a point, not an entire centerline. need to replace the subcube for a larger object but the fix for glacier_point should be done first\n",
    "    #    cl = self.centerline_main.to_crs(self.utm_crs)\n",
    "    #    line = shapely.geometry.LineString(cl.get_coordinates().loc[:,['x','y']].values)\n",
    "    #    PAD = pad #meters\n",
    "    #    line_buf = gpd.GeoSeries([line], crs=self.utm_crs).buffer(PAD, cap_style=2)\n",
    "    #    padded_cl_gdf = gpd.GeoDataFrame({'id':self.label,\n",
    "    #                              'padding':120}, index=[0], geometry=line_buf)\n",
    "    #    glacier_subcube_cl = self.datacube_sub.rio.clip(padded_cl_gdf.geometry, padded_cl_gdf.crs)\n",
    "    #    return glacier_subcube_cl\n",
    "\n",
    "    def sample_n_points(self, n ):\n",
    "        '''function to select n equally spaced points along a glacier centerline. This is how glacier_centerline object can wrap glacier_point objects\n",
    "        '''\n",
    "    #help from https://stackoverflow.com/questions/62990029/how-to-get-equally-spaced-points-on-a-line-in-shapely\n",
    "\n",
    "        distances = np.linspace(0, self.main_centerline.length*0.90, n)\n",
    "        points = [self.main_centerline.interpolate(distance) for distance in distances]\n",
    "        multipoint = unary_union(points)\n",
    "        labels = [f'point {i}' for i in range(n)]\n",
    "        coords = [(p.x, p.y) for p in multipoint.geoms]\n",
    "        xs = [coords[i][0] for i in range(len(coords))]\n",
    "        ys = [coords[i][1] for i in range(len(coords))]\n",
    "        df = pd.DataFrame({'label':labels,\n",
    "                       'x':xs,\n",
    "                       'y':ys})\n",
    "        gdf = gpd.GeoDataFrame(df, geometry = gpd.points_from_xy(df['x'], df['y'])).set_crs(self.utm_zone)\n",
    "        return gdf\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6c43d0-8dbd-4e30-87ff-a04acd63f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Glacier():\n",
    "    '''class to hold all data associated with individual glacier\n",
    "    inputs: name (str), rgi_id (str), and how the object was created (either from the map widget or manually)\n",
    "\n",
    "    NOTE: now a 'creation_flag' must be passed. this specifies if the object was created manually or \n",
    "    directly from an interaction with the widget. If created from the widget, it takes the rgi outline\n",
    "    from the clicked data, if created manually it accesses via request\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, name, rgi_id, utm_crs, creation_type, rgi_outline_from_widget='None', itslive_url='None'):\n",
    "\n",
    "        self.name = name\n",
    "        self.rgi_id = rgi_id\n",
    "        self.creation_type = creation_type\n",
    "        self._rgi_outline_from_widget = rgi_outline_from_widget\n",
    "        self._rgi_region = rgi_id.split('-')[1].split('.')[0]\n",
    "        self._outline = self._download_rgi()\n",
    "        self.utm_zone = utm_crs #fix to access utm zone from rgi outline\n",
    "        self.outline_prj = self._outline.to_crs(self.utm_zone)\n",
    "        self.itslive_url = itslive_url #this for passing to inversion script\n",
    "        #self.utm_zone = str(self.outline.estimate_utm_crs())\n",
    "        \n",
    "    def _download_rgi(self):\n",
    "        '''function to download RGI data for a specified region\n",
    "        '''\n",
    "       \n",
    "        if self.creation_type == 'widget':\n",
    "\n",
    "            data_glacier = self._rgi_outline_from_widget\n",
    "                  \n",
    "            return data_glacier\n",
    "\n",
    "        elif self.creation_type == 'manual':\n",
    "\n",
    "            region = self._rgi_region\n",
    "        \n",
    "            rgi_region_dict = {'01': 'GLIMS:RGI_Alaska', '02':  'GLIMS:RGI_WesternCanadaUS', '03':  'GLIMS:RGI_ArcticCanadaNorth',\n",
    "                           '04': 'GLIMS:RGI_ArcticCanadaSouth', '05':  'GLIMS:RGI_GreenlandPeriphery', '06': 'GLIMS:RGI_Iceland',\n",
    "                           '07':  'GLIMS:RGI_Svalbard', '08':  'GLIMS:RGI_Scandinavia', '09': 'GLIMS:RGI_RussianArctic', \n",
    "                           '10': 'GLIMS:RGI_NorthAsia', '11':  'GLIMS:RGI_CentralEurope', '12':  'GLIMS:RGI_CaucasusMiddleEast',\n",
    "                           '13':   'GLIMS:RGI_CentralAsia', '14': 'GLIMS:RGI_SouthAsiaWest', '15': 'GLIMS:RGI_SouthAsiaEast',\n",
    "                           '16':  'GLIMS:RGI_LowLatitudes', '17': 'GLIMS:RGI_SouthernAndes', '18': 'GLIMS:RGI_NewZealand',\n",
    "                           '19':  'GLIMS:RGI_AntarcticSubantarctic'}\n",
    "        \n",
    "            rgi_region_name = rgi_region_dict[region]\n",
    "        \n",
    "            rgi_url = \"https://www.glims.org/geoserver/ows?service=wms&version=1.3.0&request=GetCapabilities\"\n",
    "           \n",
    "            wfs = WebFeatureService(url=rgi_url,  version = \"2.0.0\")\n",
    "            \n",
    "            layers = list(wfs.contents)\n",
    "        \n",
    "            layer = [layers[i] for i in range(len(layers)) if layers[i] == rgi_region_name][0]\n",
    "            response = wfs.getfeature(typename = layer, outputFormat='SHAPE-ZIP')\n",
    "            data = gpd.read_file(response)\n",
    "        \n",
    "            data_glacier = data.loc[data['RGIID'] == self.rgi_id]\n",
    "            \n",
    "            return data_glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25c3112b-fc86-4321-9198-f4efec68e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class Glacier_Point():\n",
    "    '''class to hold all data associated with individual points on a glacier\n",
    "    inputs: name (str), label of point, rgi id (str), point coordinates in latlon (list)\n",
    "    '''\n",
    "    def __init__(self, name, label, rgi_id, point_coords_latlon):\n",
    "\n",
    "        self.name = name\n",
    "        self.label = label\n",
    "        self.rgi_id = rgi_id\n",
    "        self.var_ls = ['v','vy','vx','v_error','mapping','satellite_img1','satellite_img2','acquisition_date_img1', 'acquisition_date_img2']\n",
    "        #self.utm_crs = utm_crs\n",
    "        #self.glacier_gridded_data = glacier_obj.utm_gridded_data\n",
    "        #self.glacier_centerline = glacier_obj.centerline_main\n",
    "        self.point_latlon = point_coords_latlon\n",
    "        self.point_gdf = self.point_to_gdf()\n",
    "        #self.utm_crs = str(self.point_gdf.estimate_utm_crs())\n",
    "        #self.datacube_point = drop_empty_timesteps(self._add_image_pair_point())\n",
    "        self.datacube_sub = drop_empty_timesteps(self._add_image_pair_subcube())\n",
    "        self.utm_crs = str(self.datacube_sub.rio.crs)\n",
    "        #self.padded_centerline_subcube = self._extract_subcube_along_padded_centerline()\n",
    "        self.cube_around_point = drop_empty_timesteps(self._extract_3x3_cube_around_point())\n",
    "\n",
    "    def _set_var_ls(self):\n",
    "        '''this is a function that allows a user to pass their own list of variables to be pulled for hte itslive time series\n",
    "        if no alternative list is passed then the variables listed below are pulled.\n",
    "        would be good to add some sort of message with variable options, syntax requirements etc\n",
    "        '''\n",
    "        if self._non_default_var_ls == 'no':\n",
    "            \n",
    "            var_ls == ['v','vy','vx','v_error','mapping','satellite_img1','satellite_img2','acquisition_date_img1', 'acquisition_date_img2']\n",
    "        \n",
    "        else: \n",
    "            var_ls = input('Type the variables you would like to access here')\n",
    "\n",
    "            return var_ls\n",
    "            \n",
    "    def point_to_gdf(self):\n",
    "        '''This method takes the point_latlon attribute of a glacier_point class object. \n",
    "        It returns a geopandas data frame of the specified point\n",
    "        '''\n",
    "        \n",
    "        d = {'x': self.point_latlon[0],\n",
    "             'y':self.point_latlon[1]}\n",
    "        df = pd.DataFrame(d, index=[0])\n",
    "        gdf = gpd.GeoDataFrame(df, geometry = gpd.points_from_xy(df.x, df.y, crs='EPSG:4326'))\n",
    "        return gdf\n",
    "            \n",
    "    def _add_image_pair_point(self):\n",
    "        ''' uses ITS_LIVE datacube tools to access the itslive image pair time series for a given point\n",
    "        does some preliminary formatting of xarray object returned by datacubetools.get_timeseries_at_point()\n",
    "        '''\n",
    "\n",
    "        dc = datacube_tools.DATACUBETOOLS()\n",
    "        var_ls = self.var_ls \n",
    "        dc_point_full = dc.get_timeseries_at_point(self.point_latlon, point_epsg_str = '4326', variables = self.var_ls)\n",
    "        dc_point = dc_point_full[1]\n",
    "        crs = f\"EPSG:{dc_point.mapping.attrs['spatial_epsg']}\"\n",
    "        dc_point = dc_point.rio.write_crs(crs)\n",
    "        #dc_point = dc_point.rio.write_nodata(np.nan)\n",
    "        dc_point = dc_point.dropna(how='any', dim='mid_date')\n",
    "\n",
    "    \n",
    "        dc_point['acquisition_date_img1'] = (('mid_date'), pd.to_datetime(dc_point.acquisition_date_img1))\n",
    "        dc_point['acquisition_date_img2'] = (('mid_date'), pd.to_datetime(dc_point.acquisition_date_img2))\n",
    "    \n",
    "        dc_point['img_separation'] = -1*((dc_point.acquisition_date_img1 - dc_point.acquisition_date_img2).astype('timedelta64[D]') / np.timedelta64(1,'D'))\n",
    "\n",
    "        dc_point = swap_time_dim(dc_point)\n",
    "        \n",
    "        return dc_point\n",
    "\n",
    "\n",
    "    def _add_image_pair_subcube(self):\n",
    "        '''same as _add_image_pair_subcube() but uses the datacubetools method get_subcube_around_point() \n",
    "        '''\n",
    "\n",
    "        dc = datacube_tools.DATACUBETOOLS()\n",
    "        var_ls = self.var_ls\n",
    "        dc_full_sub = dc.get_subcube_around_point(self.point_latlon, point_epsg_str = '4326', variables=var_ls)\n",
    "        crs = f\"EPSG:{dc_full_sub[0].mapping.attrs['spatial_epsg']}\"\n",
    "        dc_sub = dc_full_sub[1]\n",
    "        dc_sub = dc_sub.rio.write_crs(crs)\n",
    "        dc_sub = dc_sub.dropna(how='all', dim='mid_date')\n",
    "        dc_sub['acquisition_date_img1'] = (('mid_date'), pd.to_datetime(dc_sub.acquisition_date_img1))\n",
    "        dc_sub['acquisition_date_img2'] = (('mid_date'), pd.to_datetime(dc_sub.acquisition_date_img2))\n",
    "    \n",
    "        dc_sub['img_separation'] = -1*((dc_sub.acquisition_date_img1 - dc_sub.acquisition_date_img2).astype('timedelta64[D]') / np.timedelta64(1,'D'))\n",
    "\n",
    "        dc_sub = dc_sub.dropna(how='all', dim='mid_date', subset='v')\n",
    "     \n",
    "        dc_sub = swap_time_dim(dc_sub)\n",
    "        \n",
    "        return dc_sub\n",
    "        \n",
    "    def _extract_3x3_cube_around_point(self):\n",
    "    \n",
    "        padded_point = gpd.GeoDataFrame({'id':self.label}, \n",
    "                                index=[0],\n",
    "                                geometry = self.point_gdf.to_crs(self.utm_crs).buffer(distance=200))\n",
    "        dc = self.datacube_sub.rio.clip(padded_point.geometry, padded_point.crs)\n",
    "\n",
    "        return dc\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7e4e5-36f5-44f3-9ce9-a1d8cabd9487",
   "metadata": {},
   "source": [
    "### Selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f63340-b363-4b06-90fe-9e77a730066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "data_map = interactive.Widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e21b5e-b947-445d-8480-bf761b32eee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979e0f8df3264bc2bc411dabc567d8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Map(center=[0, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', …"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "\n",
    "data_map.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a385c0c-9c6c-4d0a-9bce-8f20951c3c68",
   "metadata": {},
   "source": [
    "## Creating objects of `Glacier`, `Glacier_Centerline`, `Glacier_Point` classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e239d3-25d3-4db5-ba34-4fd60d7f6443",
   "metadata": {},
   "source": [
    "### Create directly from widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6077267-aa52-49ff-916f-d70fcb1cbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_glacier_from_click(w_obj, i):\n",
    "    '''this function takes clicked information (from a single click, not all clicked points) and returns a `Glacier` type object\n",
    "    '''\n",
    "    if len(w_obj.added_glaciers) > 0:\n",
    "        name = w_obj.added_glaciers[i]['NAME'].iloc[0]\n",
    "        rgi_id =  w_obj.added_glaciers[i]['RGIID'].iloc[0]\n",
    "        utm_crs = str(w_obj.added_glaciers[i].estimate_utm_crs())\n",
    "        rgi_gpdf = w_obj.added_glaciers[i]\n",
    "        itslive_url = w_obj.urls[i]\n",
    "        glacier = Glacier(name, rgi_id, utm_crs, 'widget', rgi_gpdf, itslive_url)\n",
    "        \n",
    "        return glacier\n",
    "\n",
    "    else:\n",
    "        print('No selection made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bba7cf6-415c-425d-8397-aee471fca040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_glacier_point_from_click(w_obj, i, label):\n",
    "    #var_ls = ['v','vy','vx','v_error','mapping','satellite_img1','satellite_img2','acquisition_date_img1', 'acquisition_date_img2']\n",
    "\n",
    "    if len(w_obj.added_glaciers) > 0:\n",
    "\n",
    "        glacier_pt = Glacier_Point(w_obj.added_glaciers[i]['NAME'], label,  w_obj.added_glaciers[i]['RGIID'].iloc[0], [w_obj.added_coords[i][1], w_obj.added_coords[i][0]])\n",
    "        #note , need to add test for cases where itslive is in a different crs than gpd.estimate_utm_crs() expects\n",
    "        return glacier_pt\n",
    "    else:\n",
    "        print('No selection made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfac855-38fe-413f-b14e-6a6410642456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def create_glacier_centerline_from_click(w_obj, i):\n",
    "\n",
    "    if len(w_obj.added_glaciers) > 0:\n",
    "        glacier_cl = Glacier_Centerline(w_obj.added_glaciers[i]['NAME'], w_obj.added_glaciers[i]['RGIID'].iloc[0])\n",
    "    \n",
    "        return glacier_cl\n",
    "\n",
    "    else: \n",
    "        print('No selection made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6deb85ec-ef88-4e03-8c24-30b02bb99728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_multiple_glacier_objs(w_obj):\n",
    "    glacier_ls = []\n",
    "    \n",
    "    if len(w_obj.added_glacier) > 0:\n",
    "\n",
    "        for i in range(len(w_obj.added_glaciers)):\n",
    "        \n",
    "            glacier = create_glacier_from_click(w_obj, i)\n",
    "            glacier_ls.append(glacier)\n",
    "    \n",
    "        return glacier_ls\n",
    "        #glacier0, glacier1 = glacier_ls[0], glacier_ls[1]\n",
    "    else:\n",
    "        print('No selection made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a790e9a8-2abf-43af-a30c-b1f5b0d5545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_multiple_glacier_point_objs(w_obj):\n",
    "\n",
    "    if len(w_obj.added_glaciers) > 0:\n",
    "        glacier_pt_ls = []\n",
    "    \n",
    "        label_ls = ['point 0','point 1']\n",
    "        \n",
    "        for i in range(len(w_obj.added_glaciers)):\n",
    "        \n",
    "            glacier_pt = create_glacier_point_from_click(w_obj,i, label_ls[i])\n",
    "            glacier_pt_ls.append(glacier_pt)\n",
    "    \n",
    "        return glacier_pt_ls\n",
    "        \n",
    "    else:\n",
    "        print('No selection made')\n",
    "   # glacier_pt0, glacier_pt1 = glacier_pt_ls[0], glacier_pt_ls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189f9e91-8036-48c2-a43d-4b38694f3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_multiple_glacier_centerline_objs(w_obj):\n",
    "    if len(w_obj.added_glaciers) > 0:\n",
    "        \n",
    "        glacier_centerline_ls = []\n",
    "    \n",
    "        for i in range(len(w_obj.added_glaciers)):\n",
    "    \n",
    "            glacier_centerline = create_glacier_centerline_from_click(w_obj, i)\n",
    "            glacier_centerline_ls.append(glacier_centerline)\n",
    "    \n",
    "        return glacier_centerline_ls\n",
    "\n",
    "    else:\n",
    "        print('No selection made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f02eae1-9971-465e-8ac0-f76a401b48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "glacier = create_glacier_from_click(data_map, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ccb070c-5efb-4ef4-b9bd-6baf0262c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original xy [76.3488006591797, 35.741827419408665] 4326 maps to datacube (621962.7934121862, 3956152.609391804) EPSG:32643\n",
      "subset and load at  56.32 seconds\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "\n",
    "glacier_pt = create_glacier_point_from_click(data_map, 0, 'test label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26238c3c-f028-441f-9134-65b73413bfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Glacier_Point at 0x7fc1e949ec50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glacier_pt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "889b080e-4779-4533-9800-6acf11f1f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "glacier_centerline = create_glacier_centerline_from_click(data_map, 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49360aea-6ced-4c98-aded-e421cf1cb0cd",
   "metadata": {},
   "source": [
    "### Create manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5ba9088-60f8-4956-ba69-61cd3016aa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CENLON</th>\n",
       "      <th>ZMAX</th>\n",
       "      <th>BGNDATE</th>\n",
       "      <th>ZMIN</th>\n",
       "      <th>RGIID</th>\n",
       "      <th>ASPECT</th>\n",
       "      <th>CENLAT</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>ZMED</th>\n",
       "      <th>...</th>\n",
       "      <th>TERMTYPE</th>\n",
       "      <th>O2REGION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ENDDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SURGING</th>\n",
       "      <th>GLIMSID</th>\n",
       "      <th>O1REGION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI_SouthAsiaWest.6794</td>\n",
       "      <td>76.4047</td>\n",
       "      <td>8569</td>\n",
       "      <td>20010721</td>\n",
       "      <td>3385</td>\n",
       "      <td>RGI60-14.06794</td>\n",
       "      <td>296</td>\n",
       "      <td>35.7416</td>\n",
       "      <td>23.8</td>\n",
       "      <td>5393</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>G076405E35742N</td>\n",
       "      <td>14</td>\n",
       "      <td>Baltoro Glacier</td>\n",
       "      <td>MULTIPOLYGON (((76.54920 35.92760, 76.54830 35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   CENLON  ZMAX   BGNDATE  ZMIN           RGIID  \\\n",
       "0  RGI_SouthAsiaWest.6794  76.4047  8569  20010721  3385  RGI60-14.06794   \n",
       "\n",
       "   ASPECT   CENLAT  SLOPE  ZMED  ...  TERMTYPE  O2REGION  STATUS   ENDDATE  \\\n",
       "0     296  35.7416   23.8  5393  ...         0         2       0  -9999999   \n",
       "\n",
       "   FORM SURGING         GLIMSID O1REGION             NAME  \\\n",
       "0     0       3  G076405E35742N       14  Baltoro Glacier   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((76.54920 35.92760, 76.54830 35...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "\n",
    "data_map.added_glaciers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1359af13-d943-42b8-9a35-99204f62d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def return_clicked_info(clicked_widget):\n",
    "\n",
    "    '''this function formats information from a user click on the Widget object. \n",
    "    The output is a tuple with the form (coordinate list of clicked point, gpd.geodataframe with rgi info of clicked glacier, url of itslive zarr datacube covering clicked point\n",
    "    '''\n",
    "    num_glaciers = len(clicked_widget.added_coords)\n",
    "    #print(len(clicked_widget.added_coords))\n",
    "    gpdf_ls = []\n",
    "    if num_glaciers > 0:\n",
    "    \n",
    "        coord_ls = clicked_widget.added_coords\n",
    "        #coord_ls = [coord_ls[0][1], coord_ls[0][0]]\n",
    "\n",
    "        gpdf_ls.append(clicked_widget.added_glaciers)\n",
    "        unique_values, unique_indices = np.unique(np.array([gpdf_ls[0][i]['RGIID'] for i in range(len(gpdf_ls[0]))]), return_index=True)\n",
    "        #adding victors code here\n",
    "        #changing obj name -- new object will be gdf_list\n",
    "        gdf_list = [gpdf_ls[0][i] for i in unique_indices]\n",
    "        #gpdf = pd.concat(gpdf_ls).drop_duplicates(subset='RGIID')\n",
    "        #adding victors code here\n",
    "        #changing obj name -- new object will be gdf_list\n",
    "       \n",
    "        print(f'You have {len(gdf_list)} glaciers selected')\n",
    "    \n",
    "        #glaciers_gpdf = pd.concat([clicked_widget.added_glacier[i] for i in range(len(clicked_widget.added_glacier))])\n",
    "    \n",
    "        urls = list(set(clicked_widget.urls))\n",
    "    \n",
    "        return (coord_ls, gdf_list, urls)\n",
    "    else: \n",
    "        print('Select a datacube to fetch the data!!')\n",
    "        #str = 'The map needs to be clicked for the appropriate object to be created'\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "293a6502-92d8-4d95-bd85-5180ebbf5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 glaciers selected\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try: \n",
    "    coords, gpdf, urls = return_clicked_info(data_map)\n",
    "    point = [coords[0][1], coords[0][0]]\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f98a5299-c83d-4c04-bb40-46b3708a9c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RGI60-14.06794'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "gpdf[0]['RGIID'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35be2314-6689-47b2-babe-44c8207ae10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://its-live-data.s3.amazonaws.com/datacubes/v2/N30E070/ITS_LIVE_vel_EPSG32643_G0120_X650000_Y3950000.zarr']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20bf18-cb54-418b-a111-1a3b5cb99f33",
   "metadata": {},
   "source": [
    "### Glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7281e9a-362e-4cb4-a102-02fcec7e1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "glacier = Glacier('name', gpdf[0]['RGIID'].iloc[0], 'EPSG:32645', 'manual', urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69d2f682-e165-41f9-818e-dbe4e1c27e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manual'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "\n",
    "glacier.creation_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1315b32b-1527-4bfe-8315-0e04e7d66a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original xy [76.47821187973024, 35.741810003130325] 4326 maps to datacube (633665.3870949473, 3956319.3552618944) EPSG:32643\n",
      "original xy [76.47821187973024, 35.741810003130325] 4326 maps to datacube (633665.3870949473, 3956319.3552618944) EPSG:32643\n",
      "subset and load at  55.22 seconds\n",
      "14605\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "glacier_pt = Glacier_Point(glacier.name, 'label', glacier.rgi_id, [coords[0][1], coords[0][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c920dc58-5088-4cd7-aac2-9677b3e0d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "glacier_centerline = Glacier_Centerline(glacier.name, glacier.rgi_id)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bc762-a9b1-4f72-a3c9-eaafd695b173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

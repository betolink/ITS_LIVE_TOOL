{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae12e1c-859d-4c9e-9009-56f6cf48f642",
   "metadata": {},
   "source": [
    "# 03: Velocity inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a76102-ce85-425b-918d-bd106a8f668d",
   "metadata": {},
   "source": [
    "# NOTE: still need to organize this code more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17710cd2-1523-4e14-9ed4-5d2f4e71573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a30185-f150-4d86-b79b-9cdfea641c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev \n",
    "from nbdev import nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b430b2e-3bac-4b7d-bd00-926b77daf2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import matplotlib.path as path\n",
    "import s3fs\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.path as mplp\n",
    "import ipyleaflet as ipyl\n",
    "from ipyleaflet import WMSLayer\n",
    "import ipywidgets as ipyw\n",
    "import json\n",
    "import pandas as pd\n",
    "from ipyleaflet import Map, WMSLayer, basemaps\n",
    "from ipywidgets import HTML\n",
    "from owslib.wms import WebMapService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731d171-1e95-4004-96c7-e8d021225caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ITS_LIVE_Analysis import setup, interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cdb3a-a8ae-46c2-873d-304f389f88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6704b-3838-4dad-88b5-5ce3c6190f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = interactive.Widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c3e89-7004-4bbe-a46f-5ff508e5504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3642af02244674a465a3bd5b1cee4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Map(center=[0, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', …"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ab3ae-c00a-439b-89f0-8ac95cb0e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, gpdf, urls = interactive.return_clicked_info(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14162e3-a723-401a-9838-2ace29cdc0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier1 = {'RGIID': gpdf.iloc[0]['RGIID'], \n",
    "           'coords': coords[0],\n",
    "            'url':urls[0],\n",
    "            'gdf':gpdf\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b632bc-696e-4e99-8cc5-35919524816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_utm_gdf = setup.point_to_gdf(glacier1['coords']).to_crs('EPSG:32643')\n",
    "coords_utm_gdf\n",
    "\n",
    "coords_utm_ls = [coords_utm_gdf['y'].iloc[0], coords_utm_gdf['x'].iloc[0]]\n",
    "coords_utm_ls\n",
    "\n",
    "urls = [glacier1['url']]\n",
    "\n",
    "gdf_list = [glacier1['gdf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19510c59-169a-4f41-996c-012c8d5ebc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://its-live-data.s3.amazonaws.com/datacubes/v2/N30E070/ITS_LIVE_vel_EPSG32643_G0120_X650000_Y3950000.zarr']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c30f50-0fff-47a1-8448-f07ae4ab39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Gather the points on the boundary of the glacier (should later be implemented as a GUI loading the points of a glacier's periphery)\n",
    "#boundary_points = pickle.load(open('boundary.p','rb'))\n",
    "\n",
    "# Modify the urls so they can be opened by zarr (replace 'http' by 's3' and delete '.s3.amazonaws.com')\n",
    "#urls = [url.replace('http','s3') for url in urls]\n",
    "try: \n",
    "    urls = [re.sub(r'http', 's3', url) for url in urls]\n",
    "    urls = [re.sub(r'\\.s3\\.amazonaws\\.com', '', url) for url in urls]\n",
    "    # Create storing arrays for the coordinates on-glacier\n",
    "    X_valid = []\n",
    "    Y_valid = []\n",
    "    X_tot = []\n",
    "    Y_tot = []\n",
    "    \n",
    "    # Create an empty directoryimport pickle to hold many variables all tied to the datacubes\n",
    "    data_dict = {}\n",
    "    \n",
    "    # We iterate through the different datacubes so they can each have one instance of the variables below\n",
    "    for url in urls:\n",
    "        zarr_store = None # To store the datacube's information and access its variables\n",
    "        dates = None # To store the dates at which the inversion will give values\n",
    "        A_m = None # 1st part of the design matrix\n",
    "        reg_mat_Inv = None # Regularization in time, 2nd part of the design matrix\n",
    "        mission = None # If you want to invert specifically for one mission in particular ('S1','L8','L9', etc...)\n",
    "        index_sort = None # Indices representing the sorted dates (from older to most recent)\n",
    "        inds_mission = None # Indices representing the sorted dates per mission chosen\n",
    "        ind_tot = None # Indices representing the indices of the pixels on the GOI\n",
    "        valid_idx = None # Easting and Northing values of the indices above\n",
    "        proj_cube = None # Projection of the datacube\n",
    "        \n",
    "        # Create a dictionary entry for the URL with the desired subsets\n",
    "        data_dict[url] = {\n",
    "            'zarr_store': zarr_store,\n",
    "            'dates': dates,\n",
    "            'A_m': A_m,\n",
    "            'reg_mat_Inv': reg_mat_Inv,\n",
    "            'mission': mission,\n",
    "            'index_sort': index_sort,\n",
    "            'inds_mission': inds_mission,\n",
    "            'dates': dates,\n",
    "            'ind_tot': ind_tot,\n",
    "            'valid_idx': valid_idx,\n",
    "            'proj_cube': proj_cube\n",
    "        }\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26469023-03f5-4721-ab40-fd4d23712bd2",
   "metadata": {},
   "source": [
    "## Datacubes Extent and Point Validity\n",
    "\n",
    "Designed to grab the extents of the datacubes, and determines which pixel belongs to the GOI. This way we do not lose time inverting for empty pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aef3fa-b7ee-4da6-942c-4762813fb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def get_extents(url, X_tot, Y_tot, X_valid, Y_valid, data_dict, mission, lamb, derivative, day_interval):\n",
    "\n",
    "    # Open the zarr files\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    store = zarr.open(s3fs.S3Map(url, s3=fs))\n",
    "   \n",
    "    # Update the dictionnary\n",
    "    data_dict[url]['zarr_store'] = store\n",
    "\n",
    "    # Get the cube's projection\n",
    "    proj_cube = store.attrs['projection']\n",
    "\n",
    "    # Load X and Y of the dataset\n",
    "    X = store['x'][:]\n",
    "    Y = store['y'][:]\n",
    "\n",
    "    # Store the arrays in the total list\n",
    "    X_tot.append(X)\n",
    "    Y_tot.append(Y)\n",
    "\n",
    "    # Load dimensions\n",
    "    shape_arr = store['v'].shape\n",
    "    \n",
    "    Xs, Ys = np.meshgrid(X, Y)\n",
    "    points = np.array((Xs.flatten(), Ys.flatten())).T\n",
    "\n",
    "    idx_valid = []\n",
    "    \n",
    "    for b in range(len(gdf_list)):\n",
    "        mpath = mplp.Path(list(gdf_list[b]['geometry'].to_crs(proj_cube).boundary.explode(index_parts = True).iloc[0].coords))\n",
    "        glacier_mask = mpath.contains_points(points).reshape(Xs.shape)\n",
    "        # Grab the indices of the points inside the glacier\n",
    "        idx_valid.append(np.array(np.where(glacier_mask==True)))\n",
    "        \n",
    "    idx_valid = np.hstack(idx_valid)\n",
    "    # Store the valid indices\n",
    "    data_dict[url]['valid_idx'] = idx_valid\n",
    "    \n",
    "    # Store the cube projection\n",
    "    data_dict[url]['proj_cube'] = proj_cube\n",
    "    \n",
    "    # Store the coordinates of the valid Xs and Ys\n",
    "    X_valid.append([Xs[idx_valid[0][i], idx_valid[1][i]] for i in range(len(idx_valid[0]))])\n",
    "    Y_valid.append([Ys[idx_valid[0][i], idx_valid[1][i]] for i in range(len(idx_valid[0]))])\n",
    "    \n",
    "    return X_tot, Y_tot, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a38758-dfea-4b37-be7f-cb32f730f417",
   "metadata": {},
   "source": [
    "## Design Matrices\n",
    "\n",
    "This function creates 1 design matrix per cube. Knowing that each cube has different time stamps (different image pairs), but the possible dates for the image pairs are the same for every pixel of the datacube, we can pre-compute 1 design-matrix for each cube. We will simply mask-out the rows that represent time steps for which our point being inverted does not have any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e098ad-fe77-4e93-81de-ee3889c4c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def design_matrices(url, mission, lamb, derivative, day_interval):\n",
    "\n",
    "    # If you passed 'mission' as an argument, it grabs the appropriate values\n",
    "    if mission:\n",
    "        # Get the indices of the mission\n",
    "        filt1 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img1'][:] == mission)\n",
    "        filt2 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img2'][:] == mission)\n",
    "        inds_mission = np.intersect1d(filt1[0],filt2[0])\n",
    "\n",
    "        # Grab only the indices corresponding to the missions\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "    else:\n",
    "        # If 'None' was passed as a mission argument, we grab all the available data.\n",
    "        inds_mission = None\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')\n",
    "    \n",
    "    # Get some arrays\n",
    "    index_sort = np.argsort(np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]'))\n",
    "    mid_dates = mid_dates[index_sort]\n",
    "    im1 = im1[index_sort]\n",
    "    im2 = im2[index_sort]\n",
    "\n",
    "\n",
    "    # Check which im is the smallest (first image, it changes depending on ITS_LIVE's version)\n",
    "    if im2[0] < im1[0]:\n",
    "        temp = im1\n",
    "        im1 = im2\n",
    "        im2 = temp\n",
    "\n",
    "\n",
    "    # Create the date array with the new interval dates\n",
    "    dates_nonum = np.arange(mid_dates[0], mid_dates[-1], timedelta(days=day_interval)).astype(np.datetime64)\n",
    "\n",
    "    # Convert to numerical\n",
    "    dates = (dates_nonum - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_start = (im1 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_end = (im2 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "\n",
    "    # --------------- DESIGN MATRICES --------------- \n",
    "\n",
    "    # Initialize matrix\n",
    "    A_m = np.zeros((mid_dates.shape[0],dates.shape[0]))\n",
    "\n",
    "    # We have to iterate through the satellite pairs that actually gave a measurement\n",
    "    for j in range(1, len(mid_dates)):\n",
    "    # current contents of your for loop\n",
    "\n",
    "        # Find the middate that is the closest to dt_start (supequal)\n",
    "        start = np.argmin(np.abs(dates-dt_start[j]))\n",
    "\n",
    "        # Find the middate that is closest to dt_end (infequal)\n",
    "        end = np.argmin(dt_end[j] - dates[dates <= dt_end[j]])\n",
    "\n",
    "        # Divide 1 by the amount of middates between d_start and d_end \n",
    "        if end == A_m.shape[1]-1: # If the mid_date is at the end of the array (acquisition im2 equals last mid_date)\n",
    "            A_m[j, start:] = 1/(1+A_m.shape[1]-start)\n",
    "        else: # If the measurement is in A's bounds temporally (we can have a satellite pair with the 2nd pair being outside of our mid_dates)\n",
    "            A_m[j, start:end+1] = 1/(1+end-start) # Attribute to each pixel in the timescale of the satellite pair, the 1/amount of pixel in the pairmid_dates.shape\n",
    "\n",
    "\n",
    "    # Initialize regularization matrix\n",
    "    if derivative == 1:\n",
    "        reg_mat_Inv = np.zeros((A_m.shape[1] -1, A_m.shape[1]))\n",
    "\n",
    "        for j in range(A_m.shape[1] -1):\n",
    "            reg_mat_Inv[j, j] = -lamb/day_interval\n",
    "            reg_mat_Inv[j, j+1] = lamb/day_interval\n",
    "\n",
    "    elif derivative == 2:\n",
    "        # Initialize 2nd derivative regularization matrix\n",
    "        reg_mat_Inv = np.zeros((A_m.shape[1] -1, A_m.shape[1]))\n",
    "\n",
    "        for j in range(A_m.shape[1] -2):\n",
    "            reg_mat_Inv[j, j] = lamb/(day_interval**2)\n",
    "            reg_mat_Inv[j, j+1] = -2*lamb/(day_interval**2)\n",
    "            reg_mat_Inv[j, j+2] = lamb/(day_interval**2)\n",
    "            \n",
    "    data_dict[urls[url]]['A_m'] = A_m\n",
    "    data_dict[urls[url]]['reg_mat_Inv'] = reg_mat_Inv\n",
    "    data_dict[urls[url]]['mission'] = mission\n",
    "    data_dict[urls[url]]['index_sort'] = index_sort\n",
    "    data_dict[urls[url]]['inds_mission'] = inds_mission\n",
    "    data_dict[urls[url]]['dates'] = dates_nonum\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c5d1e-893a-4ee5-893a-d554d1d38582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def Inv_reg(vObs, data, fillvalue):\n",
    " \n",
    "    # Grab observed velocities\n",
    "    vObs = vObs[data['index_sort']]\n",
    "    \n",
    "    # Filter out the missions we don't want\n",
    "    if mission:\n",
    "        vObs = vObs[data['inds_mission']]  \n",
    "    \n",
    "    # Mask the NaNs so we don't compute the inversion for empty rows\n",
    "    mask = np.logical_not(np.equal(vObs, fillvalue))\n",
    "    \n",
    "    # Create a masked velocity vector\n",
    "    vObs_masked = vObs[mask]\n",
    "    \n",
    "    # Append regularization terms to dObs\n",
    "    vObs_masked= np.hstack((vObs_masked, np.zeros((data['reg_mat_Inv'].shape[0]))))\n",
    "     \n",
    "    # Assemble the design matrix\n",
    "    A_des = np.vstack((data['A_m'][mask], data['reg_mat_Inv']))\n",
    "    \n",
    "    # Invert the velocities\n",
    "    vInv = np.linalg.solve(A_des.T@A_des,A_des.T@vObs_masked)\n",
    "    \n",
    "    return vInv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6665b07-514d-4580-8266-1eb94915509f",
   "metadata": {},
   "source": [
    "# **Select Your Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02639f-e65f-4d6a-8e60-b41b272bc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission = None # 'None' if you want all the data, 'S1' for Sentinel-1 only, 'L' for Landsat only, etc.. .\n",
    "lamb = 10 # Smoothing coefficient: the higher the value, the more the inversion favors a smooth output. BAD for surging glaciers, GOOD for non-surging glaciers\n",
    "derivative = 2 # Derivative degree for the inversion. Doesn't change much unless you have a specific reasong to choose 1 or 2 (1st or 2nd derivative)\n",
    "day_interval = 12 # Amount of days in between each inversion value. The higher, the faster the inversion. But you also lose in temporal resolution. 12 here because Sentinel-1 repeat-time is 12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb76354-9e87-4af7-95ef-5c31600fc61d",
   "metadata": {},
   "source": [
    "## Get extents of each datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027e81d-b161-4c6a-a6df-003ecf0c8006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                       id   CENLON  ZMAX   BGNDATE  ZMIN           RGIID  \\\n",
       " 0  RGI_SouthAsiaWest.6794  76.4047  8569  20010721  3385  RGI60-14.06794   \n",
       " \n",
       "    ASPECT   CENLAT  SLOPE  ZMED  ...  TERMTYPE  O2REGION  STATUS   ENDDATE  \\\n",
       " 0     296  35.7416   23.8  5393  ...         0         2       0  -9999999   \n",
       " \n",
       "    FORM SURGING         GLIMSID O1REGION             NAME  \\\n",
       " 0     0       3  G076405E35742N       14  Baltoro Glacier   \n",
       " \n",
       "                                             geometry  \n",
       " 0  MULTIPOLYGON (((76.54920 35.92760, 76.54830 35...  \n",
       " \n",
       " [1 rows x 24 columns]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63b000-c50d-44be-b47d-20127a413ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:28<00:00, 28.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(range(len(urls))):\n",
    "    X_tot, Y_tot, X_valid, Y_valid = get_extents(urls[url], X_tot, Y_tot, X_valid, Y_valid, data_dict, mission, lamb, derivative, day_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00161c05-6dda-4f53-a30e-5e6825dd5e3e",
   "metadata": {},
   "source": [
    "### For each datacube's valid indices (on the GOI), get the corresponding coordinates in a layer that gathers all the GOI parts spread accross the datacubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0029b-87f8-4e57-9e2b-cb46fd1980dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Eastings and Northings arrays based on the Eastings and Northings of the datacubes\n",
    "X_arr = np.unique(np.hstack(X_tot))\n",
    "Y_arr = np.unique(np.hstack(Y_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61ee9b-2e1e-4c5b-9fb0-dba98e4cdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop to the GOI (so we avoid over-filling our matrix with NaNs)\n",
    "x_min = np.where(np.min(np.hstack(X_valid)) == X_arr)[0][0]\n",
    "x_max = np.where(np.max(np.hstack(X_valid)) == X_arr)[0][0]\n",
    "y_min = np.where(np.min(np.hstack(Y_valid)) == Y_arr)[0][0]\n",
    "y_max = np.where(np.max(np.hstack(Y_valid)) == Y_arr)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e716b04-e276-4909-a09a-c44c070a17d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# And now search the indices corresponding to the coordinates \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m X_arr[\u001b[38;5;28mmin\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m Y_arr[\u001b[38;5;28mmin\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m Y_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# And now search the indices corresponding to the coordinates \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m X_arr[\u001b[38;5;28mmin\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m Y_arr[\u001b[38;5;28mmin\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m Y_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# And now search the indices corresponding to the coordinates \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m X_arr[\u001b[38;5;28mmin\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_matches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([[np\u001b[38;5;241m.\u001b[39mwhere(i \u001b[38;5;241m==\u001b[39m Y_arr[\u001b[38;5;28mmin\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\u001b[38;5;28mmax\u001b[39m(y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m Y_valid])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# And now search the indices corresponding to the coordinates \n",
    "x_matches = np.hstack([[np.where(i == X_arr[min(x_min-1, x_max+1):max(x_min-1, x_max+1)])[0][0] for i in row] for row in X_valid]).astype(int)\n",
    "y_matches = np.hstack([[np.where(i == Y_arr[min(y_min-1, y_max+1):max(y_min-1, y_max+1)])[0][0] for i in row] for row in Y_valid]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3fc90-748a-4830-96e7-ec9ff10959c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array representing the glacier\n",
    "template = np.zeros((len(Y_arr[min(y_min-1, y_max+1):max(y_min-1, y_max+1)]), len( X_arr[min(x_min-1, x_max+1):max(x_min-1, x_max+1)])))\n",
    "template[y_matches, x_matches] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2da20-2290-4162-8075-3953c6dfaa0c",
   "metadata": {},
   "source": [
    "Verify that the glacier looks as we would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541ac0e-d73e-4179-91d0-80d10f58ad37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mpcolormesh(X_arr[x_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:x_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_arr[y_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:y_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], template)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'template' is not defined"
     ]
    }
   ],
   "source": [
    "plt.pcolormesh(X_arr[x_min-1:x_max+1], Y_arr[y_min-1:y_max+1], template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37c411-52bf-4577-b21e-7c9e0a5bfbd0",
   "metadata": {},
   "source": [
    "### Create the design matrices for each datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036bbdbf-752e-445d-98ed-193450892e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(urls))):\n",
    "    design_matrices(i, mission, lamb, derivative, day_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859874a9-480d-4619-b9ca-1be98287c88b",
   "metadata": {},
   "source": [
    "### Gather dates for each datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9fe7c-a0bc-48bf-9128-c2950fd00234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total amount of temporal steps\n",
    "ind_tot = []\n",
    "for i in urls:\n",
    "    ind_tot.append(data_dict[i]['dates'])\n",
    "\n",
    "ind_tot = np.unique(np.hstack(ind_tot))\n",
    "\n",
    "for i in urls:\n",
    "    data_dict[i]['ind_tot'] = np.array([np.where(c == ind_tot)[0][0] for c in data_dict[urls[0]]['dates']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb88266-53e5-4d05-87cc-f3480e437c83",
   "metadata": {},
   "source": [
    "### Calculate the point-inversion for all the GOI pixels in the datacubes for Vx and Vy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b5e78-be88-4933-988e-dedb63c287ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vxInv = np.zeros((len(ind_tot), template.shape[0], template.shape[1]))\n",
    "vyInv = np.zeros((vxInv.shape))\n",
    "\n",
    "# Define the total number of iterations\n",
    "total_iterations = len(y_matches)\n",
    "\n",
    "# Create a tqdm object with dynamic_ncols=False to suppress intermediate updates\n",
    "# Create a tqdm object with a larger mininterval to suppress intermediate updates\n",
    "progress_bar = tqdm(total=total_iterations, dynamic_ncols=False, mininterval=1.0)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for c in range(len(urls)):\n",
    "    valid_idx = data_dict[urls[c]]['valid_idx']\n",
    "    fillvx = data_dict[urls[c]]['zarr_store']['vx'].fill_value\n",
    "    fillvy = data_dict[urls[c]]['zarr_store']['vy'].fill_value\n",
    "    \n",
    "    for V in range(len(valid_idx[0])):\n",
    "        vxObs = data_dict[urls[c]]['zarr_store']['vx'][:, valid_idx[0][V], valid_idx[1][V]]\n",
    "        vyObs = data_dict[urls[c]]['zarr_store']['vy'][:, valid_idx[0][V], valid_idx[1][V]]\n",
    "        vxInv[data_dict[urls[c]]['ind_tot'], y_matches[i], x_matches[i]] = Inv_reg(vxObs, data_dict[urls[c]], fillvx)\n",
    "        vyInv[data_dict[urls[c]]['ind_tot'], y_matches[i], x_matches[i]] = Inv_reg(vyObs, data_dict[urls[c]], fillvy)\n",
    "        \n",
    "        i += 1\n",
    "        progress_bar.update(1)  # Update the progress bar\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d9f99-06c5-41bf-83ed-e7c1f74bca42",
   "metadata": {},
   "source": [
    "### Save results to a netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4017f-ac4c-4a0a-b021-e303521d04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with vx and vy, using attributes from 'ds'\n",
    "new_ds = xr.Dataset(\n",
    "    {\n",
    "        \"vx\": ([\"time\", \"y\", \"x\"], vxInv),\n",
    "        \"vy\": ([\"time\", \"y\", \"x\"], vyInv),\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": ind_tot,\n",
    "        \"x\": X_arr[x_min-1:x_max+1],\n",
    "        \"y\": Y_arr[y_min-1:y_max+1],\n",
    "    },\n",
    "    attrs=data_dict[urls[0]]['zarr_store'].attrs,\n",
    ").chunk({'time': 1, 'x': 100, 'y': 100})\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "write_job = new_ds.to_netcdf('Inverted_Cube.nc', compute=False)\n",
    "with ProgressBar():\n",
    "    print(f\"Writing to {'Inverted_Cube.nc'}\")\n",
    "    write_job.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67247c1-f878-4e2b-9d3c-ffd7869668dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 100\n",
    "c = 0\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "test = data_dict[urls[c]]['zarr_store']['vx'][:, valid_idx[0][V], valid_idx[1][V]].astype(np.float32)\n",
    "test[test<-25000] = np.nan\n",
    "plt.scatter(data_dict[urls[c]]['zarr_store']['mid_date'][:], test, label='Observed')\n",
    "plt.plot(ind_tot, vxInv[:, y_matches[500], x_matches[500]], color = 'orange',label='Inverted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dfc55-8af6-44b3-a0bd-044fa5f945cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231b3324-7ca3-49e4-abc7-ad8a1c8af3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyproj\n",
    "import matplotlib.path as path\n",
    "import s3fs\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.path as mplp\n",
    "import ipyleaflet as ipyl\n",
    "from ipyleaflet import WMSLayer\n",
    "import ipywidgets as ipyw\n",
    "import json\n",
    "import pandas as pd\n",
    "from ipyleaflet import Map, WMSLayer, basemaps, GeoData\n",
    "from ipywidgets import HTML\n",
    "from owslib.wms import WebMapService\n",
    "import scipy\n",
    "from scipy.linalg import lu_factor, lu_solve\n",
    "from ITS_LIVE_TOOL import datacube_tools, interactive, obj_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b64db3-849a-4dd4-85e0-9c37c6f017b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "user_expressions": []
   },
   "source": [
    "### Select the datacubes overlapping your Glacier Of Interest (GOI)\n",
    "\n",
    "#### 1 left-click over each grey cube overlapping your GOI. If you make a mistake, simply restart the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9636aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = interactive.Widget()\n",
    "data_map.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5b85c-958b-4926-8aeb-0a071fcb058f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "# Theory of velocity interpolation for a single point time series\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### **Problem:**\n",
    "\n",
    "*Find a smooth regularly spaced timeseries of velocities given a set of average measurements of possibly overlapping and variable length time intervals*\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### **Start: we formulate it as an inverse problem**\n",
    "\n",
    "*Find a velocity vector $\\mathbf{v}$ that minimizes the following functional:*\n",
    "\n",
    "<br>\n",
    "\n",
    "$U(\\mathbf{v},\\lambda) = \\|\\mathbf{vInv}\\|_r + \\lambda \\|A_{m}\\mathbf{vInv} - \\mathbf{vObs}\\|$\n",
    "\n",
    "<br>\n",
    "\n",
    "- $\\mathbf{vObs}$: velocity measurements\n",
    "\n",
    "- $\\mathbf{vInv}$: vector of speeds that we are solving for at a regular interval (for example daily)\n",
    "\n",
    "- $\\|.\\|_r$: is a roughness norm (measure of the first or second derivative)\n",
    "\n",
    "- $\\lambda$: can be seen as a Lagrange multiplier (it enforces the condition in the expression behind it), or one can think of it as a relative weight of how well we want it to fit the data versus how smooth the resulting interpolated velocity should be.\n",
    "\n",
    "- $\\mathbf{A_{m}}$: indexing matrix that specifies over which time interval a velocity was measured (and averages it appropriately).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **The inversion in words**\n",
    "\n",
    "In our equation, $\\lambda$ can take several forms. In order to find a good solution, because we have prior knowledge on the ice, we can assume specific **regularization** terms: coefficients that will guide the solution towards its final shape.\n",
    "\n",
    "For example: if we look at a glacier's velocities, we can assume that the velocities close in time to each other are likely to have similar values. Same thing in space. The further away you go in space & time from your point, the less the values of these distant points will be representative of the point you're trying to invert. \n",
    "\n",
    "*In short: we \"punish\" values far in space and time so they \"weight\" less in the solution.*\n",
    "\n",
    "Mathematically, a strong regularization factor (or coefficient) in space will smoothen the output of the inversion, thus avoiding spikes in the solution. This could be very adapted for a non-surging glacier, but could completely erase a surge from a dataset. Which is why **knowing your dataset is important**.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### **Design Matrix part 1: Date Span Matrix**\n",
    "\n",
    "For a simple example, assume you want daily velocities for 6 days, and you have a measurement of the average velocity from day 1 to day 4 ($d_1$) and from day 3 to day 5 ($d_2$). We then have:\n",
    "\n",
    "$$A_{m} = \\begin{bmatrix}\n",
    "\t\t1/4 & 1/4 & 1/4 & 1/4 & 0 & 0 \\\\ \n",
    "\t\t0 & 0 & 1/3 & 1/3 & 1/3 & 0\n",
    "\t\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Dimensions:** The number of rows is equal to the number of measurements $N$ (same dimension as $\\mathbf{vObs}$) and the number of columns $M$ (same dimension as $\\mathbf{vInv}$).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Design Matrix part 2: Temporal Regularization Matrix**\n",
    "\n",
    "In order to regularize the matrix in time, we create a matrix of regularization $\\mathbf{reg_{time}}$ which dimensions are $(M-D)$ x $M$ (D is the degree of the derivative used for the regularization), for which each entry will be depending on the $\\lambda$ term and the order of the term we apply the regularization to (approximation of finite differences). The variable *h* is the set time-interval between each timestamp.\n",
    "\n",
    "**1st derivative regularization:** $f'(x) \\approx \\frac{f_{i+1} - f_{i}}{h}$  Matrix size: $(M-1)$ x $M$ \n",
    "\n",
    "Which would result in: $$reg_{time} = \\begin{bmatrix}\n",
    "\t\t\t\t\t\t\t\t\t\t-\\frac{\\lambda}{h} & \\frac{\\lambda}{h} &  &  &  & 0 \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & -\\frac{\\lambda}{h} & \\frac{\\lambda}{h}&  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & \\frac{\\lambda}{h} & \\frac{\\lambda}{h}&  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  & -\\frac{\\lambda}{h} & \\frac{\\lambda}{h}&  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t 0 &  &  &  & -\\frac{\\lambda}{h} & \\frac{\\lambda}{h} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**2nd derivative regularization:** $f''(x) \\approx \\frac{f_{i+2} - 2f_{i+1} + f_{i}}{h}$  Matrix size: $(M-2)$ x $M$ \n",
    "\n",
    "Which would result in: $$reg_{time} = \\begin{bmatrix}\n",
    "\t\t\t\t\t\t\t\t\t\t\\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  & 0 \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t 0 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Design Matrix part 3: Assemble the Design Matrix**\n",
    "And we finally obtain our main design matrix (with 2nd derivative), which is a concatenation of $A_{m}$ and $reg_{mat}$:\n",
    "\n",
    "$$A_{des} = \\begin{bmatrix}\t\t\t\t\\\\ & & A_{m} & & & \\\\ \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  & 0 \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t 0 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Extend the vector of observations**\n",
    "\n",
    "Because we added a regularization matrix to our design matrix, we need to extend our vector of observations $\\mathbf{vObs}$ so we can calculate the inversion:\n",
    "\n",
    "$$\\begin{bmatrix} v_{0} \\\\ v_{1} \\\\ ... \\\\ v_{n} \\end{bmatrix} to \\begin{bmatrix} v_{0} \\\\ v_{1} \\\\ ... \\\\ v_{n} \\\\ 0 \\\\ 0 \\\\ ... \\\\ 0 \\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "With the amount of 0s appended being $(M-1)$\n",
    "\n",
    "The obtained velocity vector is then the size of the regular matrix in time. \n",
    "(We can add a spatial regularization but it increases the computation time by 3.)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Final Part: Solve the Linear System of Equations**\n",
    "\n",
    "$A_{reg}^{T}A_{reg}\\mathbf{vInv}= A_{reg}^{T}\\mathbf{vObs}$\n",
    "\n",
    "<br>\n",
    "\n",
    "Using a linear solver (`np.linalg.solve()`, `scipy.linalg.solve()`, `torch.linalg.solve()`) find $\\mathbf{vInv}$ satisfying the equation, which is equivalent to solving: $U(\\mathbf{v},\\lambda) = \\|\\mathbf{vInv}\\|_r + \\lambda \\|A_{m}\\mathbf{vInv} - \\mathbf{vObs}\\|$. \n",
    "\n",
    "We can use a linear solver because the matrix $A_{reg}^{T}A_{reg}$ is square, symmetrical positive.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Inversion with Regularization Matrix\n",
    "<br>\n",
    "We covered the case for which we invert 1 point, with spatial regularization. Now, if we decide to include a spatial regularization, we need to fetch timeseries of points around the point we are trying to invert. Let's say we consider the eight points (0) around the point we want to invert (-):\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "\t0 & 0 & 0 \\\\\n",
    "\t0 & - & 0 \\\\\n",
    "\t0 & 0 & 0 \\\\\n",
    "\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The main difference will reside in the size of the design matrix. We have **P** points we use for the inversion (in our case, **P** = 9), the design matrix $A_{des}$ will be: \n",
    "\n",
    "$$A_{des} = \\begin{bmatrix}\t\t\t\t\\\\ A_{m} &  & &  & & &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t  & A_{m} &  & & & & & & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & A_{m} &   &   &  & 0 & &   \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & & A_{m} &  & & & & & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & &  & A_{m} &  & & & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & A_{m} &  & &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & 0 & &  & & A_{m} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & &  & A_{m} &   \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & & & & A_{m} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\treg_{time} &  & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & reg_{time} & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & reg_{time} & & & & 0 & &\\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & & reg_{time} & & & & &\\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & & & reg_{time} & & & &\\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & reg_{time} & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & 0 & & & & reg_{time} &  & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & & & reg_{time} &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & & & & & & & & reg_{time} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\treg_{time} & & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & reg_{time} & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  &  & reg_{time} & & & & 0 & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & reg_{time} & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & reg_{time} & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & 0 & & & reg_{time} & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & reg_{time} & &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & & reg_{time} &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & & & reg_{time} \\\\\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "This matrix has dimension $P*N + 2P*(M-D)$ x $P*M$.\n",
    "\n",
    "#### **Spatial Regularization Matrix**\n",
    "\n",
    "The spatial regularization matrix has the same entries than the temporal regularization matrix. It consists in stacking temporal regularization matrices on the diagonal, but also under the matrix *of the point we want to invert*:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "\t\t\t\t\t\t\t\t\t\treg_{time} & & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & reg_{time} & & & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  &  & reg_{time} & & & & 0 & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & reg_{time} & & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & reg_{time} & & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & 0 & & & reg_{time} & & & \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & reg_{time} & &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & & reg_{time} &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\treg_{time}  & & & & & & & & reg_{time} \\\\\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "Its dimensions are $P*(M-D)$ x $M$. It is possible to choose the a Jacobian or Hessian differently than the temporal regularization matrix. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### **Observation Vector:**\n",
    "\n",
    "In the case we have multiple points, we can simply stack the observations of the multiple points, and extend the result with 0s to match the row space of the temporal and spatial regularization matrices: \n",
    "\n",
    "$$\\begin{bmatrix} v1_{0} \\\\ v1_{1} \\\\ ... \\\\ v1_{n} \\\\ v2_{0} \\\\ ... \\\\ v2_{n} \\\\ ... \\\\ vP_{n} \\end{bmatrix} to \\begin{bmatrix} v1_{0} \\\\ v1_{1} \\\\ ... \\\\ v1_{n} \\\\ v2_{0} \\\\ ... \\\\ v2_{n} \\\\ ... \\\\ vP_{n} \\\\ 0 \\\\ 0 \\\\ ... \\\\ 0 \\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "# Inversion applied to ITS_LIVE\n",
    "\n",
    "#### **ITS_LIVE primary issue:**\n",
    "\n",
    "ITS_LIVE is a great dataset that achieves high-density measurements globally, on a long timescale, using the same sensors and method.\n",
    "However it suffers from one main problem: **mid_dates**, its attribution of a timestamp for a measurement.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 1:** ITS_LIVE uses two images to calculate the velocity of the ice. 1st image is acquired on *January 1st*, 2nd image is acquired on *January 15th*.\n",
    "\n",
    "We obtain an average velocity over 15 days: $v = \\frac{displacement}{15 days} = 10 m/day$\n",
    "\n",
    "The problem is that ITS_LIVE will attribute this velocity to a **precise point in time** rather than a **period of time**: the velocity of $10 m/day$ is attributed to *January 7th* at Noon. This is physically wrong.\n",
    "\n",
    "It is difficult to work with periods of time, while precise points in time are much more convenient, which is probably why ITS_LIVE organizes its data like that.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 2:** We now have 2 measurements of velocities:\n",
    "- **V1**: $10 m/day$, timestamp: *January 7th*, Date 1st image acquisition: *January 1st*, Date 2nd image acquisition: *January 15th*  \n",
    "- **V2**: $5 m/day$, timestamp: *January 12th*, Date 1st image acquisition: *January 5th*, Date 2nd image acquisition: *January 19th*  \n",
    "\n",
    "ITS_LIVE would put only 2 timestamps. However there is more information than just during those two days. The intersection between the two measurements procures information on the average velocity between *January 5th* and *January 15th*. Because we now have a fragmentation of each acquisition into smaller segments, we can also derive refined average velocities for the following periods of time:\n",
    "- *January 1st* and *January 5th*\n",
    "- *January 5th* and *January 7th*\n",
    "- *January 7th* and *January 12th*\n",
    "- *January 12th* and *January 15th*\n",
    "- *January 15th* and *January 19th*\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Inversion theory applied to ITS_LIVE:**\n",
    "\n",
    "Let's consider the same setup at in **Example 2**.\n",
    "We want to linearize in time to force a sampling of velocities 2 days. Thus, our matrix $A_{m}$ will have 2 rows (we have 2 average velocities given by ITS_LIVE), and 10 columns (19 days between the first and last acquisition dates: *January 1st* and *January 19th*, divided by 2 because we force 2 days sampling):\n",
    "\n",
    "$$dates = \\begin{bmatrix}\n",
    "\t\t1st & 3rd & 5th & 7th & 9th & 11th & 13th & 15th & 17th & 19th\n",
    "\t\t\\end{bmatrix}$$\n",
    "\n",
    "$$A_{m} = \\begin{bmatrix}\n",
    "\t\t1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 0    &    0   \\\\ \n",
    "\t\t0    &    0 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14\n",
    "\t\t\\end{bmatrix}$$\n",
    "<br>\n",
    "\n",
    "In the matrix above, each column is paired with a date (matrix 'dates). The first row of $A_{m}$ corresponds to the first velocity measurement. Because this measurement is the average velocity from *January 1st* to *January 15th*, every day in between has *1/15* attributed to it in the matrix (15 days, each contributing equally to the velocity observed). \n",
    "The 2nd row, representing the 2nd velocity measurement (or observed) spans 14 days hence why the values there are *1/14*. Note that when a day is not covered by the velocity time period, the value is 0.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assemble the design matrix:** (regularization in time with 2nd derivative, Jacobian):\n",
    "\n",
    "\n",
    "$$A_{reg} = \\begin{bmatrix}\t\t\t\t1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 0    &    0  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t0    &    0 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14\t \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  &  &  &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  & 0 &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & 0 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Extend the vector $\\mathbf{vObs}$:**\n",
    "\n",
    "$$\\mathbf{vObs} = \\begin{bmatrix} v1 \\\\ v2 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} $$\n",
    "\n",
    "**Solve the linear system of equation:**\n",
    "\n",
    "$$\\begin{bmatrix}\t\t\t\t        1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 1/15 & 0    &    0  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t0    &    0 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14 & 1/14\t \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  &  &  &  \\\\ \n",
    "\t\t\t\t\t\t\t\t\t\t & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  & 0 &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  & 0 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix} \n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t\\begin{bmatrix}\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 0 & \\frac{\\lambda}{h^{2}} & &  &  &  &  &  & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 0 & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  & 0 & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}  & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  & 0 &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t0    & 1/14 &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & 2\\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t0    & 1/14 &  &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}}\\\\ \n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}\\mathbf{vInv}$$\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "$$ = $$\n",
    "$$\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\begin{bmatrix}\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 0 & \\frac{\\lambda}{h^{2}} & &  &  &  &  &  & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 0 & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  & 0 & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}} &  \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}  & \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t1/15 & 1/14 &  & 0 &  &  &  & \\frac{\\lambda}{h^{2}} & -2\\frac{\\lambda}{h^{2}} & \\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t0    & 1/14 &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}} & 2\\frac{\\lambda}{h^{2}}\\\\\n",
    "\t\t\t\t\t\t\t\t\t\t0    & 1/14 &  &  &  &  &  &  &  & \\frac{\\lambda}{h^{2}}\\\\ \n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\\end{bmatrix}\\begin{bmatrix} v1 \\\\ v2 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \n",
    "\t\t\t\t\t\t\t\t\t\t$$\n",
    "\n",
    "**You end up with $\\mathbf{vInv}$**\n",
    "\n",
    "<br>\n",
    "\n",
    "**End:**\n",
    "\n",
    "You now have the vector of inverted velocities ! It is basically an interpolation of $vObs$ but linearized in time (regular timesteps) and by weighing multiple parameters that can be tuned depending on your knowledge of the glacier.\n",
    "\n",
    "The Gaussian Process and Glacier Point methods should give you an idea of how your glacier flows, and how to apply the inversion the best way possible. Now, run the code below (similar to the code in roadmap), and try to identify which part of the code corresponds to the theory ! \n",
    "\n",
    "<br>\n",
    "\n",
    "### **Input your parameters below**\n",
    "\n",
    "*Useful information:*\n",
    "\n",
    "- GPU generally runs the inversion faster, but might be slower when using the spatial regularization.\n",
    "- High lambda encouraged for non-surging glacier\n",
    "- spatial_shape 'ring' if you have a GPU/CPU with a lot of RAM (>16Gb), use 'cross' otherwise\n",
    "- spatial_regularization: False if you want a faster computation, slightly less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f57bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission = None # 'None' if you want all the data, 'S1' for Sentinel-1 only, 'L' for Landsat only, etc.. .\n",
    "\n",
    "lamb = 10 # Smoothing coefficient: the higher the value, the more the inversion favors a smooth output. BAD for surging glaciers, GOOD for non-surging glaciers\n",
    "\n",
    "derivative = 2 # Derivative degree for the inversion. Doesn't change much unless you have a specific reasong to choose 1 or 2 (1st or 2nd derivative)\n",
    "\n",
    "day_interval = 12 # Amount of days in between each inversion value. The higher, the faster the inversion. But you also lose in temporal resolution. 12 here because Sentinel-1 repeat-time is 12.\n",
    "\n",
    "sdate = None # Start date, format 'YYYY-MM-DD' OR None if you want to grab the entire timeseries available\n",
    "\n",
    "edate = None # End date, format 'YYYY-MM-DD' OR None if you want to grab the entire timeseries available\n",
    "\n",
    "spatial_shape = 'cross' # or 'ring'\n",
    "\n",
    "GPU = True # True if you want to use GPU, False if you want to use CPU\n",
    "\n",
    "spatial_regularization = True # True if you want to use spatial regularization, False if you only want to use temporal regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641489ab",
   "metadata": {},
   "source": [
    "## Select your data\n",
    "\n",
    "If you already have datacube/glaciers selected, run the next cell as is. \n",
    "Otherwise, uncomment and run, and re-select your glacier of interest.\n",
    "\n",
    "\n",
    "#### **Instructions:**\n",
    "\n",
    "- Right-click on a glacier to get its RGI ID. It should illuminate in blue once you have selected it. You can select multiple glaciers.\n",
    "\n",
    "    **WARNING:** if you are on a web browser (Cryocloud, OpenScienceLab, etc...): right-click will open a pop-up menu. Simply left-click somewhere on your screen to make it disappear.\n",
    "\n",
    "- Left-click on the datacube (*grey* overlay, *red* when you hover your mouse over it) you want to download. You can select multiple datacubes.\n",
    "    When a datacube URL has been fetched, it should print it below the GUI.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_map = interactive.Widget()\n",
    "#data_map.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e68c9b",
   "metadata": {},
   "source": [
    "**Create dictionnaries to hold variables for each datacube**\n",
    "\n",
    "Each datacube has multiple variables associated with it. We gather all these variables in dictionnaries such as 1 datacube = 1 dictionnary.\n",
    "We then gather all the dictionnaries into one for easier organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1462c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the points on the boundary of the glacier (should later be implemented as a GUI loading the points of a glacier's periphery)\n",
    "#boundary_points = pickle.load(open('boundary.p','rb'))\n",
    "\n",
    "# Modify the urls so they can be opened by zarr (replace 'http' by 's3' and delete '.s3.amazonaws.com')\n",
    "urls = [re.sub(r'http', 's3', url) for url in urls]\n",
    "urls = [re.sub(r'\\.s3\\.amazonaws\\.com', '', url) for url in urls]\n",
    "\n",
    "# Create an empty directoryimport pickle to hold many variables all tied to the datacubes\n",
    "data_dict = {}\n",
    "\n",
    "# We iterate through the different datacubes so they can each have one instance of the variables below\n",
    "for url in urls:\n",
    "    zarr_store = None # To store the datacube's information and access its variables\n",
    "    dates = None # To store the dates at which the inversion will give values\n",
    "    A_m = None # 1st part of the design matrix\n",
    "    reg_mat_Inv = None # Regularization in time, 2nd part of the design matrix\n",
    "    mission = None # If you want to invert specifically for one mission in particular ('S1','L8','L9', etc...)\n",
    "    index_sort = None # Indices representing the sorted dates (from older to most recent)\n",
    "    inds_mission = None # Indices representing the sorted dates per mission chosen\n",
    "    ind_tot = None # Indices representing the indices of the pixels on the GOI\n",
    "    valid_idx = None # Easting and Northing values of the indices above\n",
    "    proj_cube = None # Projection of the datacube\n",
    "    mask_dates = None # Mask that filters out dates outside of desired date range\n",
    "    reg_mat_space_Inv = None # Space regularization matrix\n",
    "    reg_mat_time_Inv = None # Time regularization matrix\n",
    "    \n",
    "    # Create a dictionary entry for the URL with the desired subsets\n",
    "    data_dict[url] = {\n",
    "        'zarr_store': zarr_store,\n",
    "        'dates_noinv': dates,\n",
    "        'A_m': A_m,\n",
    "        'reg_mat_time_Inv': reg_mat_time_Inv,\n",
    "        'reg_mat_space_Inv': reg_mat_space_Inv,\n",
    "        'mission': mission,\n",
    "        'index_sort': index_sort,\n",
    "        'inds_mission': inds_mission,\n",
    "        'dates': dates,\n",
    "        'ind_tot': ind_tot,\n",
    "        'valid_idx': valid_idx,\n",
    "        'proj_cube': proj_cube,\n",
    "        'mask_dates': mask_dates\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962f045",
   "metadata": {},
   "source": [
    "## Datacubes Extent and Point Validity\n",
    "\n",
    "Designed to grab the extents of the datacubes, and determines which pixel belongs to the GOI (Glacier Of Interest). This way we do not lose time inverting for empty pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aeceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extents(url, X_tot, Y_tot, X_valid, Y_valid, data_dict, mission, lamb, derivative, day_interval):\n",
    "\n",
    "    # Open the zarr files\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    store = zarr.open(s3fs.S3Map(url, s3=fs))\n",
    "   \n",
    "    # Update the dictionnary\n",
    "    data_dict[url]['zarr_store'] = store\n",
    "\n",
    "    # Get the cube's projection\n",
    "    proj_cube = store.attrs['projection']\n",
    "\n",
    "    # Load X and Y of the dataset\n",
    "    X = store['x'][:]\n",
    "    Y = store['y'][:]\n",
    "\n",
    "    # Store the arrays in the total list\n",
    "    X_tot.append(X)\n",
    "    Y_tot.append(Y)\n",
    "\n",
    "    # Load dimensions\n",
    "    shape_arr = store['v'].shape\n",
    "    \n",
    "    Xs, Ys = np.meshgrid(X, Y)\n",
    "    points = np.array((Xs.flatten(), Ys.flatten())).T\n",
    "\n",
    "    idx_valid = []\n",
    "    \n",
    "    for b in range(len(gdf_list)):\n",
    "        mpath = mplp.Path(gdf_list[b]['geometry'].to_crs(proj_cube).boundary.explode(index_parts = True).iloc[0].coords[:])\n",
    "        glacier_mask = mpath.contains_points(points).reshape(Xs.shape)\n",
    "        # Grab the indices of the points inside the glacier\n",
    "        idx_valid.append(np.array(np.where(glacier_mask==True)))\n",
    "        \n",
    "    idx_valid = np.hstack(idx_valid)\n",
    "    # Store the valid indices\n",
    "    data_dict[url]['valid_idx'] = idx_valid\n",
    "    \n",
    "    # Store the cube projection\n",
    "    data_dict[url]['proj_cube'] = proj_cube\n",
    "    \n",
    "    # Store the coordinates of the valid Xs and Ys\n",
    "    X_valid.append([Xs[idx_valid[0][i], idx_valid[1][i]] for i in range(len(idx_valid[0]))])\n",
    "    Y_valid.append([Ys[idx_valid[0][i], idx_valid[1][i]] for i in range(len(idx_valid[0]))])\n",
    "    \n",
    "    return X_tot, Y_tot, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f05e7",
   "metadata": {},
   "source": [
    "## Design Matrices\n",
    "\n",
    "This function creates 1 design matrix per cube. Knowing that each cube has different time stamps (different image pairs), but the possible dates for the image pairs are the same for every pixel of the datacube, we can pre-compute 1 design-matrix for each cube. We will simply mask-out the rows that represent time steps for which our point being inverted does not have any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_matrices(url, mission, lamb, derivative, day_interval, sdate, edate, nb_pts):\n",
    "\n",
    "    # If you passed 'mission' as an argument, it grabs the appropriate values\n",
    "    if mission:\n",
    "        # Get the indices of the mission\n",
    "        filt1 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img1'][:] == mission)\n",
    "        filt2 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img2'][:] == mission)\n",
    "        inds_mission = np.intersect1d(filt1[0],filt2[0])\n",
    "\n",
    "        # Grab only the indices corresponding to the missions\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "    else:\n",
    "        # If 'None' was passed as a mission argument, we grab all the available data.\n",
    "        inds_mission = None\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')\n",
    "    \n",
    "    # Get some arrays\n",
    "    index_sort = np.argsort(np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]'))\n",
    "    mid_dates = mid_dates[index_sort]\n",
    "    im1 = im1[index_sort]\n",
    "    im2 = im2[index_sort]\n",
    "\n",
    "    # If sdate is later than the first available date, we find its corresponding index\n",
    "    try:\n",
    "        sdate_ind = np.where(mid_dates >= sdate)[0][0]\n",
    "    except:\n",
    "        sdate_ind = 0\n",
    "    \n",
    "    # If edate is sooner than the last available date, we find its corresponding index\n",
    "    try:\n",
    "        edate_ind = np.where(mid_dates > edate)[0][0]\n",
    "    except:\n",
    "        edate_ind = None\n",
    "    \n",
    "    # Create a False/True mask where True if the date is in the desired range\n",
    "    mask_dates = np.full(mid_dates.shape, False)\n",
    "    mask_dates[sdate_ind:edate_ind] = True\n",
    "\n",
    "    # Keep only the values within the desired range\n",
    "    mid_dates = mid_dates[mask_dates]\n",
    "    im1 = im1[mask_dates]\n",
    "    im2 = im2[mask_dates]\n",
    "\n",
    "    # Check which im is the smallest (first image, it changes depending on ITS_LIVE's version)\n",
    "    if im2[0] < im1[0]:\n",
    "        temp = im1\n",
    "        im1 = im2\n",
    "        im2 = temp\n",
    "\n",
    "    # Create the date array with the new interval dates, from the first date available to two time intervals after ther last date available (python bounds thing)\n",
    "    dates_nonum = np.arange(im1[0], im2[-1]+(day_interval*2), timedelta(days=day_interval)).astype(np.datetime64)\n",
    "\n",
    "    # Convert to numerical\n",
    "    dates = (dates_nonum - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_start = (im1 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_end = (im2 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "\n",
    "    # --------------- DESIGN MATRICES --------------- \n",
    "\n",
    "    # If you passed 'mission' as an argument, it grabs the appropriate values\n",
    "    if mission:\n",
    "        # Get the indices of the mission\n",
    "        filt1 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img1'][:] == mission)\n",
    "        filt2 = np.where(data_dict[urls[url]]['zarr_store']['satellite_img2'][:] == mission)\n",
    "        inds_mission = np.intersect1d(filt1[0],filt2[0])\n",
    "\n",
    "        # Grab only the indices corresponding to the missions\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')[inds_mission]\n",
    "    else:\n",
    "        # If 'None' was passed as a mission argument, we grab all the available data.\n",
    "        inds_mission = None\n",
    "        mid_dates = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]')\n",
    "        im1 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img1'][:], dtype='timedelta64[D]')\n",
    "        im2 = np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['acquisition_date_img2'][:], dtype='timedelta64[D]')\n",
    "    \n",
    "    # Get some arrays\n",
    "    index_sort = np.argsort(np.datetime64('1970-01-01') + np.array(data_dict[urls[url]]['zarr_store']['mid_date'][:], dtype='timedelta64[D]'))\n",
    "    mid_dates = mid_dates[index_sort]\n",
    "    im1 = im1[index_sort]\n",
    "    im2 = im2[index_sort]\n",
    "\n",
    "    # If sdate is later than the first available date, we find its corresponding index\n",
    "    try:\n",
    "        sdate_ind = np.where(mid_dates >= sdate)[0][0]\n",
    "    except:\n",
    "        sdate_ind = 0\n",
    "    \n",
    "    # If edate is sooner than the last available date, we find its corresponding index\n",
    "    try:\n",
    "        edate_ind = np.where(mid_dates > edate)[0][0]\n",
    "    except:\n",
    "        edate_ind = None\n",
    "    \n",
    "    # Create a False/True mask where True if the date is in the desired range\n",
    "    mask_dates = np.full(mid_dates.shape, False)\n",
    "    mask_dates[sdate_ind:edate_ind] = True\n",
    "\n",
    "    # Keep only the values within the desired range\n",
    "    mid_dates = mid_dates[mask_dates]\n",
    "    im1 = im1[mask_dates]\n",
    "    im2 = im2[mask_dates]\n",
    "\n",
    "    # Check which im is the smallest (first image, it changes depending on ITS_LIVE's version)\n",
    "    if im2[0] < im1[0]:\n",
    "        temp = im1\n",
    "        im1 = im2\n",
    "        im2 = temp\n",
    "\n",
    "    # Create the date array with the new interval dates, from the first date available to two time intervals after ther last date available (python bounds thing)\n",
    "    dates_nonum = np.arange(im1[0], im2[-1]+(day_interval*2), timedelta(days=day_interval)).astype(np.datetime64)\n",
    "\n",
    "    # Convert to numerical\n",
    "    dates = (dates_nonum - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_start = (im1 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    dt_end = (im2 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
    "    delta_t = dates[1]-dates[0] # Calculate delta time between two dates\n",
    "\n",
    "    # Initialize matrix\n",
    "    A_m = np.zeros((mid_dates.shape[0],dates.shape[0]))\n",
    "\n",
    "    # We have to iterate through the satellite pairs that actually gave a measurement\n",
    "    for j in range(1, len(mid_dates)):\n",
    "    # current contents of your for loop\n",
    "        beg_dates = (dates[dates<=dt_start[j]] - dt_start[j]) # Get the dates inferior or equal to the 1st acquisition's date\n",
    "        beg_diff =  delta_t + beg_dates[-1] # Calculate the difference between the closest date supequal to the 1st acquisition's date\n",
    "        \n",
    "        # If the 1st acquisition's date falls exactly on a date, then their difference in time is 0. Otherwise, we calculate it.\n",
    "        if beg_diff == 0:\n",
    "            start = len(beg_dates) - 1\n",
    "        else:\n",
    "            start = len(beg_dates)\n",
    "            A_m[j, start-1:start] = beg_diff\n",
    "            \n",
    "        \n",
    "        \n",
    "        end_ind = np.where(dates == dates[dates>=dt_end[j]][0])[0][0] # Get the closest date supequal to the 2nd acquisition's date\n",
    "        end_diff = delta_t - (dates[end_ind] - dt_end[j]) # Calculate the difference between this date and the 2nd acquisition's date\n",
    "        \n",
    "        # If the 2nd acquisition's date falls exactly on a date, then their difference in time is 0. Otherwise, we calculate it.\n",
    "        if end_diff == 0:\n",
    "            end = end_ind\n",
    "        else:\n",
    "            end = end_ind - 1\n",
    "            A_m[j, end:end+1] = end_diff\n",
    "        \n",
    "        A_m[j, start:end] = delta_t # For every whole interval, attribute the value of the delta time\n",
    "        A_m[j] /= ((dt_end[j]-dt_start[j])) # Divide everything by the time difference between acquisition 1 and 2. Results are convex (add up to 1)\n",
    "      \n",
    "        \n",
    "    # Initialize regularization matrix\n",
    "    if derivative == 1:\n",
    "        reg_time_temp = np.zeros((A_m.shape[1] -1, A_m.shape[1]))\n",
    "\n",
    "        for j in range(A_m.shape[1] -1):\n",
    "            reg_time_temp[j, j] = -lamb/day_interval\n",
    "            reg_time_temp[j, j+1] = lamb/day_interval\n",
    "\n",
    "    elif derivative == 2:\n",
    "        # Initialize 2nd derivative regularization matrix\n",
    "        reg_time_temp = np.zeros((A_m.shape[1] -2, A_m.shape[1]))\n",
    "\n",
    "        for j in range(A_m.shape[1] -2):\n",
    "            reg_time_temp[j, j] = lamb/(day_interval**2)\n",
    "            reg_time_temp[j, j+1] = -2*lamb/(day_interval**2)\n",
    "            reg_time_temp[j, j+2] = lamb/(day_interval**2)\n",
    "    reg_mat_time = reg_time_temp\n",
    "    \n",
    "    # Spatial regularization matrix\n",
    "    reg_mat_space = np.tile(reg_mat_time, (nb_pts, 1))\n",
    "            \n",
    "    data_dict[urls[url]]['A_m'] = A_m\n",
    "    data_dict[urls[url]]['reg_mat_time_Inv'] = reg_mat_time\n",
    "    data_dict[urls[url]]['reg_mat_space_Inv'] = reg_mat_space\n",
    "    data_dict[urls[url]]['mission'] = mission\n",
    "    data_dict[urls[url]]['index_sort'] = index_sort\n",
    "    data_dict[urls[url]]['inds_mission'] = inds_mission\n",
    "    data_dict[urls[url]]['dates'] = dates_nonum\n",
    "    data_dict[urls[url]]['dates_noinv'] = mid_dates\n",
    "    data_dict[urls[url]]['mask_dates']= mask_dates\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7e943",
   "metadata": {},
   "source": [
    "### Get the extents of each datacube\n",
    "\n",
    "We map which pixels of the datacubes are on-glacier, and we save their coordinates in X/Y_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179776c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create storing arrays for the coordinates on-glacier\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "X_tot = []\n",
    "Y_tot = []\n",
    "for url in tqdm(range(len(urls))):\n",
    "    X_tot, Y_tot, X_valid, Y_valid = get_extents(urls[url], X_tot, Y_tot, X_valid, Y_valid, data_dict, mission, lamb, derivative, day_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206042c9",
   "metadata": {},
   "source": [
    "### Map the valid indices in a new array\n",
    "\n",
    "This new array spans all the datacubes. We take the footprint of the GOI, insert-it in an array, and map in this array which pixel is on-glacier.\n",
    "It allows to run the inversion for glacier-points only, accross all the datacubes, and store the inversion output in an array that represents the glacier's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Eastings and Northings arrays based on the Eastings and Northings of the datacubes\n",
    "X_arr = np.unique(np.hstack(X_tot))\n",
    "Y_arr = np.unique(np.hstack(Y_tot))\n",
    "\n",
    "# Crop to the GOI (so we avoid over-filling our matrix with NaNs)\n",
    "x_min = np.where(np.min(np.hstack(X_valid)) == X_arr)[0][0]\n",
    "x_max = np.where(np.max(np.hstack(X_valid)) == X_arr)[0][0]\n",
    "y_min = np.where(np.min(np.hstack(Y_valid)) == Y_arr)[0][0]\n",
    "y_max = np.where(np.max(np.hstack(Y_valid)) == Y_arr)[0][0]\n",
    "\n",
    "# Define the boundaries of the GOI.\n",
    "X_MIN = min(x_min-1, x_max+1)\n",
    "X_MAX = max(x_min-1, x_max+1)\n",
    "Y_MIN = min(y_min-1, y_max+1)\n",
    "Y_MAX = max(y_min-1, y_max+1)\n",
    "\n",
    "# If the GOI is not entirely covered by the datacubes, we need to crop the GOI so it fits the datacube. If not, then we expand the GOI to fit the datacube.\n",
    "if X_MIN < 0:\n",
    "    X_MIN = 0\n",
    "if X_MAX > len(X_arr):\n",
    "    X_MAX = len(X_arr)\n",
    "if Y_MIN < 0:\n",
    "    Y_MIN = 0\n",
    "if Y_MAX > len(Y_arr):\n",
    "    Y_MAX = len(Y_arr)\n",
    "\n",
    "\n",
    "# And now search the indices corresponding to the coordinates \n",
    "x_matches = np.hstack([[np.where(i == X_arr[X_MIN:X_MAX])[0][0] for i in row] for row in X_valid]).astype(int)\n",
    "y_matches = np.hstack([[np.where(i == Y_arr[Y_MIN:Y_MAX])[0][0] for i in row] for row in Y_valid]).astype(int)\n",
    "coords_matches = list(zip(y_matches, x_matches))\n",
    "\n",
    "# Create an array representing the glacier\n",
    "template = np.zeros((len(Y_arr[Y_MIN:Y_MAX]), len( X_arr[X_MIN:X_MAX])))\n",
    "template[y_matches, x_matches] = 1\n",
    "\n",
    "# Determine to which datacube each match belongs to\n",
    "arr_belong = np.zeros((len(y_matches)))\n",
    "p = 0\n",
    "for i in range(len(urls)):\n",
    "    arr_belong[p:data_dict[urls[i]]['valid_idx'].shape[1]+p] = i\n",
    "    p += data_dict[urls[i]]['valid_idx'].shape[1]\n",
    "cube_belong = np.full((len(Y_arr[Y_MIN:Y_MAX]), len( X_arr[X_MIN:X_MAX])), -1)\n",
    "cube_belong[y_matches, x_matches] = arr_belong\n",
    "    \n",
    "    \n",
    "# Concatenate valid indices for the cubes\n",
    "neighbor_idx = []\n",
    "for i in range(len(urls)):\n",
    "    neighbor_idx.append(data_dict[urls[i]]['valid_idx'])\n",
    "neighbor_idx = np.hstack(neighbor_idx)\n",
    "\n",
    "# Create a 2D array the size of template that links neighbor_idx entries and their position in the 2D template\n",
    "position = np.zeros(template.shape, dtype = int)\n",
    "for i in range(len(y_matches)):\n",
    "    position[y_matches[i], x_matches[i]] = i    \n",
    "\n",
    "# Create a list that gathers the coordinates of central points and their neighboring points, their respective cubes and position in flattened template\n",
    "P = [[]]\n",
    "\n",
    "# Get the search shape\n",
    "if spatial_shape == 'cross':\n",
    "    nb_pts_tot = 5\n",
    "    # Define the offsets for the surrounding cells\n",
    "    offsets = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "elif spatial_shape == 'ring':\n",
    "    nb_pts_tot = 9\n",
    "    # Define the offsets for the surrounding cells\n",
    "    offsets = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "\n",
    "for i in range(len(y_matches)):\n",
    "   # Iterate over each surrounding cell\n",
    "    sum_surrounding = 0\n",
    "    pt = []\n",
    "    pt.append([y_matches[i], x_matches[i], cube_belong[y_matches[i], x_matches[i]], position[y_matches[i], x_matches[i]]])\n",
    "\n",
    "    if spatial_regularization:\n",
    "        for offset in offsets:\n",
    "    \n",
    "            surrounding_i = y_matches[i] + offset[0]\n",
    "            surrounding_j = x_matches[i] + offset[1]\n",
    "    \n",
    "            # Check if the coordinates are within the array bounds\n",
    "            if (0 <= surrounding_i < template.shape[0] and\n",
    "                0 <= surrounding_j < template.shape[1]):\n",
    "                # Check if the value of the surrounding cell is 1\n",
    "                if template[surrounding_i, surrounding_j] == 1:\n",
    "                    sum_surrounding += 1\n",
    "                    pt.append([surrounding_i, surrounding_j, cube_belong[surrounding_i, surrounding_j], position[surrounding_i, surrounding_j]])\n",
    "    P.append(pt)\n",
    "\n",
    "# Get rid of first entry (which is empty)\n",
    "P = P[1:]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c825dbc",
   "metadata": {},
   "source": [
    "Verify that the glacier looks like what we would expect (mind the projection, specifically where North direction should be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cdab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fc1830fb990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(X_arr[X_MIN:X_MAX], Y_arr[Y_MIN:Y_MAX], template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae655d0",
   "metadata": {},
   "source": [
    "### Create the design matrices for each datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4400028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3122/4053961409.py:58: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dates = (dates_nonum - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "/tmp/ipykernel_3122/4053961409.py:59: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dt_start = (im1 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "/tmp/ipykernel_3122/4053961409.py:60: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dt_end = (im2 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "/tmp/ipykernel_3122/4053961409.py:119: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dates = (dates_nonum - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "/tmp/ipykernel_3122/4053961409.py:120: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dt_start = (im1 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "/tmp/ipykernel_3122/4053961409.py:121: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  dt_end = (im2 - np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(urls))):\n",
    "    design_matrices(i, mission, lamb, derivative, day_interval, sdate, edate, nb_pts_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194f0b1",
   "metadata": {},
   "source": [
    "### Gather the dates for each datacube. They might not always correspond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total amount of temporal steps\n",
    "ind_tot = []\n",
    "for i in urls:\n",
    "    ind_tot.append(data_dict[i]['dates'])\n",
    "\n",
    "ind_tot = np.unique(np.hstack(ind_tot))\n",
    "\n",
    "for i in urls:\n",
    "    data_dict[i]['ind_tot'] = np.array([np.where(c == ind_tot)[0][0] for c in data_dict[urls[0]]['dates']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ef950",
   "metadata": {},
   "source": [
    "### Function to loop through every valid on-glacier pixel.\n",
    "\n",
    "The following function calls the point's timeseries from ITS_LIVE, assembles the design matrix, and calls the inversion function. Once it is done, it stores the inversion output in the host matrices (vx & vy). It saves a copy of the matrices as a netcdf object every 10k iterations, and creates a text file printing how many iterations have been computed, every 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looper(i, GPU, spatial_regularization, nb_pts_tot, time_reg_mat, space_reg_mat):\n",
    "    \n",
    "    global vxInv\n",
    "    global vyInv\n",
    "    \n",
    "    # Get all the points used in the inversion. 1st point is the one we are inverting for\n",
    "    vxObs = [np.array(data_dict[urls[P[i][v][2]]]['zarr_store']['vx'][:,  neighbor_idx[:,P[i][v][3]][0], neighbor_idx[:,P[i][v][3]][1]][data_dict[urls[P[i][v][2]]]['index_sort']][data_dict[urls[P[i][v][2]]]['mask_dates']], dtype=np.float64) for v in range(len(P[i]))]\n",
    "    vyObs = [np.array(data_dict[urls[P[i][v][2]]]['zarr_store']['vy'][:,  neighbor_idx[:,P[i][v][3]][0], neighbor_idx[:,P[i][v][3]][1]][data_dict[urls[P[i][v][2]]]['index_sort']][data_dict[urls[P[i][v][2]]]['mask_dates']], dtype=np.float64) for v in range(len(P[i]))]\n",
    "\n",
    "    # Grab the nodata value\n",
    "    fillvalue = vxObs[0].min()\n",
    "\n",
    "    # Get the length of the first point\n",
    "    len_pt_inverted = data_dict[urls[P[i][0][2]]]['dates'].shape[0]\n",
    "    \n",
    "    # Mask the non-valid values\n",
    "    mask = [np.logical_not(np.equal(vxObs[v], fillvalue)) for v in range(len(vxObs))]\n",
    "\n",
    "    # Mask the observed vectors\n",
    "    vxObs_masked = [vxObs[v][mask[v]] for v in range(len(vxObs))]\n",
    "    vyObs_masked = [vyObs[v][mask[v]] for v in range(len(vyObs))]\n",
    "\n",
    "    # Get the length of each point\n",
    "    len_pts_tot =  [len(vxObs_masked[v]) for v in range(len(vxObs))]\n",
    "\n",
    "    # Stack the observed vectors\n",
    "    vxObs_masked = np.hstack(vxObs_masked)\n",
    "    vyObs_masked = np.hstack(vyObs_masked)\n",
    "\n",
    "    # Count the amount of points\n",
    "    nb_pts = len(P[i])\n",
    "\n",
    "    # Assemble the design matrix, masked \n",
    "    # Initialize the design matrix\n",
    "    if spatial_regularization:\n",
    "        A_des = np.zeros((len(vxObs_masked) + 2*SRT[0]*nb_pts , SRT[1]*nb_pts))\n",
    "    \n",
    "        # Fill-in the values of A_m depending on each point\n",
    "        cr = 0\n",
    "        cc = 0\n",
    "        for v in range(nb_pts):\n",
    "            A_des[cr:cr+len_pts_tot[v], cc:cc+len_pt_inverted] = data_dict[urls[P[i][v][2]]]['A_m'][mask[v]]\n",
    "            cr += len_pts_tot[v]\n",
    "            cc += len_pt_inverted\n",
    "\n",
    "        # Append time and spatial regularizatiJohn Lopezon matrices, fitted to the amount of points we have\n",
    "        A_des[cr:cr + SRT[0]*nb_pts, :] = time_reg_mat[:SRT[0]*nb_pts, :SRT[1]*nb_pts]\n",
    "        A_des[cr + SRT[0]*nb_pts:, :] = space_reg_mat[:SRT[0]*nb_pts, :SRT[1]*nb_pts]\n",
    "\n",
    "    else:\n",
    "        A_des = np.zeros((len(vxObs_masked) + SRT[0], SRT[1]))\n",
    "        cr = len_pts_tot[0]\n",
    "        cc = len_pt_inverted\n",
    "        A_des[:cr] = data_dict[urls[P[i][0][2]]]['A_m'][mask[0]]\n",
    "        A_des[cr:cr + SRT[0], :] = time_reg_mat[:SRT[0], :SRT[1]]\n",
    "\n",
    "\n",
    "    # Invert the velocities\n",
    "    vxInv[: , y_matches[i], x_matches[i]] = Inverter(GPU, spatial_regularization, vxObs_masked, nb_pts, len_pt_inverted, A_des, device)\n",
    "    vyInv[: , y_matches[i], x_matches[i]] = Inverter(GPU, spatial_regularization, vyObs_masked, nb_pts, len_pt_inverted, A_des, device)\n",
    "    \n",
    "    \n",
    "    # Save the amount of iterations in a text file\n",
    "    if i%100 == 0:\n",
    "        with open(\"Counter.txt\", \"w\") as text_file:\n",
    "            text_file.write(f\"Counter: {i}\")\n",
    "\n",
    "    # Save the matrices along-the-way in case the algorithm fails\n",
    "    if i%10000 == 0 and i != 0:\n",
    "\n",
    "        print(f\"Saved at {i}\")\n",
    "        \n",
    "        # Get the names of all the glaciers in the datacube \n",
    "        new_ds = xr.Dataset(\n",
    "            {\n",
    "                \"vx\": ([\"time\", \"y\", \"x\"], vxInv.cpu().numpy()),\n",
    "                \"vy\": ([\"time\", \"y\", \"x\"], vyInv.cpu().numpy())\n",
    "            },\n",
    "            coords={\n",
    "                \"time\": ind_tot,\n",
    "                \"x\": X_arr[X_MIN:X_MAX],\n",
    "                \"y\": Y_arr[Y_MIN:Y_MAX]\n",
    "            },\n",
    "            attrs=data_dict[urls[0]]['zarr_store'].attrs,\n",
    "        ).chunk({'time': 1, 'x': 100, 'y': 100})\n",
    "\n",
    "        from dask.diagnostics import ProgressBar\n",
    "        write_job = new_ds.to_netcdf(f'Cube.nc', compute=False)\n",
    "        with ProgressBar():\n",
    "            print(f\"Writing to {'Cube.nc'}\")\n",
    "            write_job.compute()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4283e20",
   "metadata": {},
   "source": [
    "#### Inversion function\n",
    "\n",
    "The function determines if we use GPU acceleration or not, and finds the optimal solution for a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inverter(GPU, spatial_regularization, vObs_masked, nb_pts, len_pt_inverted, A_des, device):\n",
    "\n",
    "    # Extend the observations with 0s to match the length of spacetime regularizations\n",
    "    if spatial_regularization:\n",
    "        vObs_masked = np.hstack((vObs_masked, np.zeros((2*SRT[0]*nb_pts))))\n",
    "    else:\n",
    "        vObs_masked = np.hstack((vObs_masked, np.zeros((SRT[0]))))\n",
    "\n",
    "    if GPU:\n",
    "        # Migrate velocity vector to torch\n",
    "        vObs_masked = torch.from_numpy(vObs_masked).to(device).double()\n",
    "        # Migrate design matrix to GPU\n",
    "        A_des = torch.from_numpy(A_des).to(device)\n",
    "        vInv = torch.linalg.solve(A_des.T@A_des,A_des.T@(vObs_masked))[:len_pt_inverted].cpu()\n",
    "    else:\n",
    "        vInv = np.linalg.solve(A_des.T@A_des,A_des.T@(vObs_masked))[:len_pt_inverted]\n",
    "\n",
    "    return vInv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a1c19",
   "metadata": {},
   "source": [
    "#### Design Matrix components\n",
    "\n",
    "Build the last bricks of the design matrix depending on how many points we use in the regularization & initialize host arrays for the inversion outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_reg_mat = np.zeros((nb_pts_tot*data_dict[urls[0]]['reg_mat_time_Inv'].shape[0], nb_pts_tot*data_dict[urls[0]]['reg_mat_time_Inv'].shape[1]))\n",
    "SRT = data_dict[urls[0]]['reg_mat_time_Inv'].shape\n",
    "# Stack time_reg_temp on the diagonal of time_reg\n",
    "for i in range(0,nb_pts_tot):\n",
    "    time_reg_mat[i*SRT[0]:(i+1)*SRT[0], i*SRT[1]:(i+1)*SRT[1]] = data_dict[urls[0]]['reg_mat_time_Inv']\n",
    "\n",
    "\n",
    "# Initialize spatial regulization matrix\n",
    "space_reg_mat = np.zeros((time_reg_mat.shape[0], time_reg_mat.shape[1]))\n",
    "\n",
    "for i in range(0,nb_pts_tot):\n",
    "\n",
    "    if i == 0:\n",
    "        space_reg_mat[:, i*SRT[1]:(i+1)*SRT[1]] = data_dict[urls[0]]['reg_mat_space_Inv']\n",
    "\n",
    "    elif i != 0:\n",
    "        space_reg_mat[(i)*SRT[0]:(i+1)*SRT[0], i*SRT[1]:(i+1)*SRT[1]] = data_dict[urls[0]]['reg_mat_time_Inv']\n",
    "\n",
    "\n",
    "# Initialize velocity matrices\n",
    "vxInv = np.zeros((len(ind_tot), template.shape[0], template.shape[1]))\n",
    "vyInv = np.zeros((vxInv.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc153c8",
   "metadata": {},
   "source": [
    "# Run the inversion\n",
    "\n",
    "If GPU then we import the necessary package and variable\n",
    "At the end, store as a netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c53782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 839/17924 [11:47<3:59:57,  1.19it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if GPU:     \n",
    "    import torch\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = None\n",
    "\n",
    "# Run the inversions for vx and vy and populate vxInv, vyInv\n",
    "for i in tqdm(range(len(y_matches))):\n",
    "\n",
    "    looper(i, GPU, spatial_regularization, nb_pts_tot, time_reg_mat, space_reg_mat)    \n",
    "\n",
    " \n",
    "# Save the dataset\n",
    "new_ds = xr.Dataset(\n",
    "{\n",
    "    \"vx\": ([\"time\", \"y\", \"x\"], vxInv),\n",
    "    \"vy\": ([\"time\", \"y\", \"x\"], vyInv),\n",
    "},\n",
    "coords={\n",
    "    \"time\": ind_tot,\n",
    "    \"x\": X_arr[X_MIN:X_MAX],\n",
    "    \"y\": Y_arr[Y_MIN:Y_MAX]\n",
    "},\n",
    "attrs=data_dict[urls[0]]['zarr_store'].attrs,\n",
    ").chunk({'time': 1, 'x': 100, 'y': 100})\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "write_job = new_ds.to_netcdf(f'Cube.nc', compute=False)\n",
    "with ProgressBar():\n",
    "    print(f\"Writing to {'Cube.nc'}\")\n",
    "    write_job.compute()   \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gaussian",
   "language": "python",
   "name": "gaussian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
